{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18472d4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaca74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pykdtree.kdtree import KDTree\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9055c8",
   "metadata": {},
   "source": [
    "# Hyperparameter and Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bc5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! SETUP !!\n",
    "\n",
    "# Problem to consider\n",
    "# Either \"stokes\", \"advection\" or \"graetz\"\n",
    "pname = 'stokes'\n",
    "\n",
    "# Training data\n",
    "# Note: model assumes data equally split among different fidelities\n",
    "# Loss is computed as the sum of the mse losses weighted by number\n",
    "# of samples\n",
    "train_mesh_names = ['reference_mesh.npy']\n",
    "train_solution_names = ['matrix.mat']\n",
    "assert len(train_mesh_names) == len(train_solution_names)\n",
    "\n",
    "# Testing meshes\n",
    "test_mesh_names = ['reference_mesh_large.npy', 'reference_mesh.npy', 'reference_mesh_small.npy', 'reference_mesh_tiny.npy']\n",
    "test_solution_names = ['matrix_large.mat', 'matrix.mat', 'matrix_small.mat', 'matrix_tiny.mat']\n",
    "assert len(train_mesh_names) == len(train_solution_names)\n",
    "\n",
    "# Naming convention for saving the model\n",
    "save_name = 'best_model_l_single_.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f582d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! MODEL INITIALISATION !!\n",
    "\n",
    "# Set the initial mesh for the model\n",
    "# If intending to do mode 'adaptive' then set equal to largest training mesh\n",
    "# Otherwise, select as desired\n",
    "initial_mesh = 'reference_mesh_large.npy'\n",
    "\n",
    "# Select precision\n",
    "# (explanation for when this can matter at https://blog.demofox.org/2017/11/21/floating-point-precision/)\n",
    "precision = torch.float32\n",
    "\n",
    "# Latent dimension\n",
    "latent_size = 20\n",
    "\n",
    "# Mapper sizes\n",
    "# Mapper maps from parameters to latent dimension\n",
    "# We optionally allow the addition of further layers\n",
    "mapper_sizes = [50, 50, 50, 50]\n",
    "\n",
    "# Autoencoder sizes\n",
    "# Autoencoder maps from full data to latent representation\n",
    "# We optionally allow the addition of further layers\n",
    "ae_sizes = []\n",
    "gfn_latent_size = 20\n",
    "\n",
    "# Activation\n",
    "act=nn.Tanh\n",
    "\n",
    "# Seed for reproducibility\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271d5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! TRAINING !!\n",
    "\n",
    "# Use either fixed (\"fixed\"), adaptive (\"adapt\") or precomputed adaptive method (\"preadapt\")\n",
    "mode = 'fixed'\n",
    "\n",
    "# Weight to give to the mapper loss compared to the autoencoder loss\n",
    "mapper_weight = 1e1\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 5#000\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# L2 regularisation hyperparamter\n",
    "lambda_ = 10**-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7f5cd",
   "metadata": {},
   "source": [
    "# Setup Training Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d10e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_dtype(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dbce6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(pname='stokes'):\n",
    "    if pname == 'stokes':\n",
    "        mu_range = [(0.5,1.5), (0.5,1.5), (0.5,1.5), (0.5,1.5), (0.5,1.5), (-np.pi/6,np.pi/6), (-10,10)]\n",
    "        mus = []\n",
    "        n_pts = [2]*(len(mu_range)-1)+[11]\n",
    "        for i in range(len(mu_range)):\n",
    "            mus.append(np.linspace(mu_range[i][0], mu_range[i][1], n_pts[i]))\n",
    "        return torch.tensor(np.array(list(product(*mus))), dtype=precision)\n",
    "    elif pname == 'graetz':\n",
    "        mus = [np.linspace(1., 3., 10), np.linspace(0.01, 0.1, 20)]\n",
    "        mu1, mu2 = np.meshgrid(mus[0], mus[1])\n",
    "        return torch.tensor(np.vstack((mu1.T, mu2.T)).reshape(2, -1).T, dtype=precision)\n",
    "    elif pname == 'advection':\n",
    "        mus = [np.linspace(0., 6., 10), np.linspace(-1.0, 1.0, 10)]\n",
    "        mu1, mu2 = np.meshgrid(mus[0], mus[1])\n",
    "        return torch.tensor(np.vstack((mu1.T, mu2.T)).reshape(2, -1).T, dtype=precision)\n",
    "\n",
    "def scaler_func():\n",
    "    return preprocessing.StandardScaler()\n",
    "\n",
    "def scaling(U):\n",
    "    scaling_fun_1 = scaler_func()\n",
    "    scaling_fun_2 = scaler_func()\n",
    "    scaler_s = scaling_fun_1.fit(U)\n",
    "    temp = torch.t(torch.tensor(scaler_s.transform(U)))\n",
    "    scaler_f = scaling_fun_2.fit(temp)\n",
    "    scaled_data = torch.unsqueeze(torch.t(torch.tensor(scaler_f.transform(temp), dtype=precision)),0).permute(2, 1, 0)\n",
    "    scale = [scaler_s, scaler_f]\n",
    "    return scale, scaled_data[:,:,0]\n",
    "\n",
    "def undo_scaling(U, scale):\n",
    "    scaler_s = scale[0]\n",
    "    scaler_f = scale[1]\n",
    "    rescaled_data = torch.tensor(scaler_s.inverse_transform(torch.t(torch.tensor(scaler_f.inverse_transform(U.detach().numpy().squeeze())))), dtype=precision)\n",
    "    return rescaled_data\n",
    "\n",
    "def get_scaled_data(fname):\n",
    "    U_orig = torch.tensor(scipy.io.loadmat(fname)['U'])\n",
    "    scale, U_sc = scaling(U_orig)\n",
    "    print('reconstruction error', ((U_orig - undo_scaling(U_sc, scale))**2).sum())\n",
    "    return scale, U_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffeaf30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error tensor(2.4297e-09, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Get parameter space we examine\n",
    "params = get_params(pname).to(dev)\n",
    "n_params = params.shape[1]\n",
    "\n",
    "# Load training data\n",
    "meshes_train = [np.load(i) for i in train_mesh_names]\n",
    "sols_train = [get_scaled_data(i)[1].to(dev) for i in train_solution_names]\n",
    "# Assert that meshes and solutions have same numbers of points\n",
    "assert np.mean([meshes_train[i].shape[0] == sols_train[i].shape[1] for i in range(len(meshes_train))]) == 1\n",
    "# Assert that solutions are present for all the parameter realisations\n",
    "assert np.mean([params.shape[0] == i.shape[0] for i in sols_train]) == 1\n",
    "\n",
    "# Split parameter space for training and testing\n",
    "trajs = list(range(params.shape[0]))\n",
    "random.shuffle(trajs)\n",
    "train_trajs, test_trajs = np.array_split(trajs, 2)\n",
    "train_trajs = np.array_split(train_trajs, len(meshes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe62108",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mesh = np.load(initial_mesh)\n",
    "\n",
    "expand_master = mode == 'preadapt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24005f33",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057d826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFN_AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Module implementing the GFN method for the encoder and decoder architectures.\n",
    "    \"\"\"\n",
    "    def __init__(self, mesh_m, latent_size=20):\n",
    "        super().__init__()\n",
    "        size = mesh_m.shape[0]\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        # Set up master mesh and master weights\n",
    "        # NB: cheaper not to make parameters if we're planning on updating sizes\n",
    "        self.We_m = nn.Parameter(torch.empty(size, self.latent_size))\n",
    "        self.be_m = nn.Parameter(torch.empty(self.latent_size))\n",
    "        self.Wd_m = nn.Parameter(torch.empty(self.latent_size, size))\n",
    "        self.bd_m = nn.Parameter(torch.empty(size))\n",
    "        self.mesh_m = mesh_m\n",
    "        \n",
    "        # Initialise weights\n",
    "        self.initialise(self.We_m, self.be_m)\n",
    "        self.initialise(self.Wd_m, self.bd_m)\n",
    "        \n",
    "        # Set up the weight matrices and mesh used for inference\n",
    "        # Note: no self.be_n since we never need to reshape the encoder biases i.e. be_n == be_m in all cases\n",
    "        self.We_n = self.We_m.clone()\n",
    "        self.Wd_n = self.Wd_m.clone()\n",
    "        self.bd_n = self.bd_m.clone()\n",
    "        \n",
    "    def initialise(self, weight, bias):\n",
    "        stdv = 1. / math.sqrt(weight.size(1))\n",
    "        weight.data.uniform_(-stdv, stdv)\n",
    "        bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def reshape_weights(self, mesh_n, update_master=False, expand=True, agglomerate=True, kd_tree_m=None, kd_tree_n=None, nn_m=None, nn_n=None):\n",
    "        \"\"\"\n",
    "        mesh_n: New geometry to evaluate on\n",
    "        update_master: Whether or not to update the master mesh during the reshaping. Must always\n",
    "                        be False during inference. For 'fixed' or 'preadapt' methods, should be\n",
    "                        False. For 'adapt', should be True during training.\n",
    "        expand: Whether or not the new geometry requires expanding the master mesh\n",
    "        agglomerate: Whether or not the new geometry requires agglomerating the master mesh\n",
    "        kd_tree_m: A precomputed kdtree using nodes in the master mesh\n",
    "        kd_tree_n: A precomputed kdtree using nodes in the new mesh\n",
    "        nn_m: List of nearest neighbours for nodes in the master mesh (i.e. indices of nodes in the new mesh)\n",
    "        nn_n: List of nearest neighbours for nodes in the new mesh (i.e. indices of nodes in the master mesh)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find nearest neighbours if we don't already know them\n",
    "        if nn_n is not None:\n",
    "            pass\n",
    "        elif kd_tree_n is not None:\n",
    "            nn_n = kd_tree_m.query(mesh_n, k=1)[1]\n",
    "        else:\n",
    "            kd_tree_m = KDTree(self.mesh_m)\n",
    "            nn_n = kd_tree_m.query(mesh_n, k=1)[1]\n",
    "        if nn_m is not None:\n",
    "            pass\n",
    "        elif kd_tree_n is not None:\n",
    "            nn_m = kd_tree_n.query(self.mesh_m, k=1)[1]\n",
    "        else:\n",
    "            kd_tree_n = KDTree(mesh_n)\n",
    "            nn_m = kd_tree_n.query(self.mesh_m, k=1)[1]\n",
    "\n",
    "        # WE HAVE TWO CASES TO CONSIDER:\n",
    "        # Case 1: We are either in evaluation mode or we are in training with `update_master=False`\n",
    "        # Case 2: We are in training with `update_master=True`\n",
    "        \n",
    "        # How much did we expand or agglomerate?\n",
    "        nodes_added = 0\n",
    "        nodes_combined = 0\n",
    "\n",
    "        # !! EXPANSION !!\n",
    "        if expand:\n",
    "            # Case 1: master mesh isn't updated\n",
    "            if not update_master or not self.training:\n",
    "                # Set up intermediate variable so we do not update We_m\n",
    "                if self.training:\n",
    "                    We_i = self.We_m.clone()\n",
    "                    Wd_i = self.Wd_m.clone()\n",
    "                    bd_i = self.bd_m.clone()\n",
    "                else:\n",
    "                    We_i = self.We_m\n",
    "                    Wd_i = self.Wd_m\n",
    "                    bd_i = self.bd_m\n",
    "            \n",
    "                # Set up counters\n",
    "                count_m = np.zeros(self.mesh_m.shape[0])\n",
    "                size = self.mesh_m.shape[0]\n",
    "\n",
    "                # Loop over each pt_n_{M_n} with its pair pt_m_{M_m} <- pt_n_{M_n}\n",
    "                for pt_n, pt_m in enumerate(nn_n):\n",
    "                    # if NOT pt_m_{M_m} <-> pt_n_{M_n}\n",
    "                    if nn_m[pt_m] != pt_n:\n",
    "                        nodes_added += 1\n",
    "                        count_m[pt_m] += 1\n",
    "\n",
    "                        # Divide encoder weights by number of expansions\n",
    "                        We_i[pt_m] *= count_m[pt_m]/(count_m[pt_m]+1)\n",
    "                        # Store the index of the weight we want\n",
    "                        # so we can update at the end without storing\n",
    "                        # all the nodes to update explictly\n",
    "                        new_row = torch.zeros(1, We_i.shape[1])\n",
    "                        new_row[0][0] = pt_m\n",
    "                        We_i = torch.cat((We_i, new_row), dim=0)\n",
    "                        \n",
    "                        # Duplicate weights for decoder\n",
    "                        Wd_i = torch.cat((Wd_i, Wd_i[:, pt_m:pt_m+1]), dim=1)\n",
    "                        bd_i = torch.cat([bd_i, bd_i[pt_m:pt_m+1]])\n",
    "\n",
    "                        # Directly add nearest neighbour link\n",
    "                        nn_m = np.append(nn_m, pt_n)\n",
    "                \n",
    "                # Loop over the nodes we need to update using the index we stored in the first element\n",
    "                for i in range(size, size+nodes_added):\n",
    "                    index = int(We_i[i,0])\n",
    "                    We_i[i] = We_i[index]\n",
    "\n",
    "            # Case 2: master mesh is updated (only happens if model.train())\n",
    "            else:\n",
    "                # We overwrite master mesh so we can ignore gradient tracking\n",
    "                with torch.no_grad():\n",
    "                    # Set up counters\n",
    "                    count_m = np.zeros(self.mesh_m.shape[0])\n",
    "                    nodes_added = 0\n",
    "                    size = self.mesh_m.shape[0]\n",
    "\n",
    "                    # Loop over each pt_n_{M_n} with its pair pt_m_{M_m} <- pt_n_{M_n}\n",
    "                    for pt_n, pt_m in enumerate(nn_n):\n",
    "                        # if NOT pt_m_{M_m} <-> pt_n_{M_n}\n",
    "                        if nn_m[pt_m] != pt_n:\n",
    "                            nodes_added += 1\n",
    "                            count_m[pt_m] += 1\n",
    "\n",
    "                            # Divide encoder weights by number of expansions\n",
    "                            self.We_m[pt_m] *= count_m[pt_m]/(count_m[pt_m]+1)\n",
    "                            # Store the index of the weight we want\n",
    "                            # so we can update at the end without storing\n",
    "                            # all the nodes to update explictly\n",
    "                            new_row = torch.zeros(1, self.We_m.shape[1], device=self.We_m.device)\n",
    "                            new_row[0][0] = pt_m\n",
    "                            self.We_m = torch.cat((self.We_m, new_row), dim=0)\n",
    "                            \n",
    "                            # Duplicate weights for decoder\n",
    "                            self.Wd_m = torch.cat((self.Wd_m, self.Wd_m[:, pt_m:pt_m+1]), dim=1)\n",
    "                            self.bd_m = torch.cat([self.bd_m, self.bd_m[pt_m:pt_m+1]])\n",
    "\n",
    "                            # Directly add nearest neighbour link\n",
    "                            nn_m = np.append(nn_m, pt_n)\n",
    "                            \n",
    "                            # Update master mesh\n",
    "                            self.mesh_m = np.vstack([self.mesh_m, mesh_n[pt_n]])\n",
    "                    \n",
    "                    # Loop over the nodes we need to update using the index we stored in the first element\n",
    "                    for i in range(size, size+nodes_added):\n",
    "                        index = int(self.We_m[i,0])\n",
    "                        self.We_m[i] = self.We_m[index]\n",
    "\n",
    "                We_i = self.We_m.clone()\n",
    "                Wd_i = self.Wd_m.clone()\n",
    "                bd_i = self.bd_m.clone()\n",
    "\n",
    "        # If we don't expand\n",
    "        else:\n",
    "            if self.training:\n",
    "                We_i = self.We_m.clone()\n",
    "                Wd_i = self.Wd_m.clone()\n",
    "                bd_i = self.bd_m.clone()\n",
    "            else:\n",
    "                We_i = self.We_m\n",
    "                Wd_i = self.Wd_m\n",
    "                bd_i = self.bd_m\n",
    "\n",
    "        # !! AGGLOMERATION !!\n",
    "        if agglomerate:\n",
    "            self.We_n = torch.zeros((mesh_n.shape[0], self.We_m.shape[1]), device=self.We_m.device)\n",
    "            self.Wd_n = torch.zeros((self.We_m.shape[1], mesh_n.shape[0]), device=self.We_m.device)\n",
    "            self.bd_n = torch.zeros(mesh_n.shape[0], device=self.We_m.device)\n",
    "\n",
    "            count_n = np.zeros(mesh_n.shape[0])\n",
    "\n",
    "            # Loop over each pt_m_{M_m} with its pair pt_m_{M_m} -> pt_n_{M_n}\n",
    "            for pt_m, pt_n in enumerate(nn_m):\n",
    "\n",
    "                count_n[pt_n]+=1\n",
    "                if count_n[pt_n]>1:\n",
    "                    nodes_combined+=1\n",
    "\n",
    "                # Summation\n",
    "                self.We_n[pt_n] += We_i[pt_m]\n",
    "                # Calculate Mean\n",
    "                self.Wd_n[:, pt_n] = ( (count_n[pt_n]-1)*self.Wd_n[:, pt_n] + Wd_i[:, pt_m] )/count_n[pt_n]\n",
    "                self.bd_n[pt_n] = ( (count_n[pt_n]-1)*self.bd_n[pt_n] + bd_i[pt_m] )/count_n[pt_n]\n",
    "\n",
    "        # If we don't agglomerate        \n",
    "        else:\n",
    "            self.We_n = We_i[nn_m]\n",
    "            self.Wd_n = Wd_i[:,nn_m]\n",
    "            self.bd_n = bd_i[nn_m]\n",
    "            \n",
    "        return nodes_added, nodes_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab40e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFN_ROM(nn.Module):\n",
    "    \n",
    "    def __init__(self, mesh_m, gfn_latent_size=20, latent_size=20, n_params=7, act=nn.Tanh, ae_sizes=[], map_sizes=[50]*4):\n",
    "        super().__init__()\n",
    "        self.GFN = GFN_AE(mesh_m, gfn_latent_size)\n",
    "        \n",
    "        self.act = act()\n",
    "        \n",
    "        module_list_enc = []\n",
    "        module_list_dec = []\n",
    "\n",
    "        for i in range(len(ae_sizes)):\n",
    "            module_list_dec.append(self.act)\n",
    "            if i==0:\n",
    "                module_list_enc.append(nn.Linear(gfn_latent_size, ae_sizes[i]))\n",
    "                module_list_dec.append(nn.Linear(ae_sizes[i], gfn_latent_size))\n",
    "            else:\n",
    "                module_list_enc.append(nn.Linear(ae_sizes[i-1], ae_sizes[i]))\n",
    "                module_list_dec.append(nn.Linear(ae_sizes[i], ae_sizes[i-1]))\n",
    "            module_list_enc.append(self.act)\n",
    "        if len(ae_sizes)!=0:\n",
    "            module_list_dec.append(self.act)\n",
    "            module_list_enc.append(nn.Linear(ae_sizes[-1], latent_size))\n",
    "            module_list_dec.append(nn.Linear(latent_size, ae_sizes[-1]))\n",
    "            module_list_enc.append(self.act)\n",
    "        \n",
    "        self.encoder = nn.Sequential(*module_list_enc)\n",
    "        self.decoder = nn.Sequential(*module_list_dec[::-1])\n",
    "        \n",
    "        module_list_map = []\n",
    "        \n",
    "        for i in range(len(map_sizes)):\n",
    "            if i==0:\n",
    "                module_list_map.append(nn.Linear(n_params, map_sizes[i]))\n",
    "            else:\n",
    "                module_list_map.append(nn.Linear(map_sizes[i-1], map_sizes[i]))\n",
    "            module_list_map.append(act())\n",
    "        if len(map_sizes)!=0:\n",
    "            module_list_map.append(nn.Linear(map_sizes[-1], latent_size))\n",
    "            \n",
    "        self.mapper = nn.Sequential(*module_list_map)\n",
    "        \n",
    "    def forward(self, x, mesh_n, params, update_master=False, expand=True, agglomerate=True, kd_tree_m=None, kd_tree_n=None, nn_m=None, nn_n=None):\n",
    "        n_exp, n_agg = self.GFN.reshape_weights(mesh_n, update_master, expand, agglomerate, kd_tree_m, kd_tree_n, nn_m, nn_n)\n",
    "        \n",
    "        x_enc = self.act(x@self.GFN.We_n+self.GFN.be_m)\n",
    "        x_enc = self.encoder(x_enc)\n",
    "        \n",
    "        x_map = self.mapper(params)\n",
    "        \n",
    "        x_recon = self.decoder(x_enc)\n",
    "        x_recon = x_recon@self.GFN.Wd_n+self.GFN.bd_n\n",
    "        \n",
    "        return x_recon, x_enc, x_map, n_exp, n_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5ba89",
   "metadata": {},
   "source": [
    "# Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fa4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7020, 2)\n"
     ]
    }
   ],
   "source": [
    "model = GFN_ROM(start_mesh, gfn_latent_size, latent_size, n_params, act, ae_sizes, mapper_sizes).to(dev)\n",
    "print(model.GFN.mesh_m.shape)\n",
    "\n",
    "# We do all of the possible expansions apriori in the preadaptive case\n",
    "# This is a preprocessing step so we don't do any speedup steps here\n",
    "if mode=='preadapt':\n",
    "    count = 0\n",
    "    while count!=0:\n",
    "        count = 0\n",
    "        for mesh_n in meshes_train:\n",
    "            n_exp, n_agg = model.GFN.reshape_weights(mesh_n, update_master=True)\n",
    "            count += n_exp\n",
    "    print(model.GFN.mesh_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834c95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:90: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "if not expand_master:\n",
    "    opt = torch.optim.Adam(list(model.parameters())+[model.GFN.We_m, model.GFN.be_m, model.GFN.Wd_m, model.GFN.bd_m], lr=lr, weight_decay=lambda_)\n",
    "else:\n",
    "    # Cannot update GFN parameters using Adam anymore since we use adaptive method\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lambda_)\n",
    "    \n",
    "    raise Exception(\"Have not yet implemented GD for the GFN parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bd139",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69cd7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "\n",
    "def criterion(x, x_recon, x_enc, x_map):\n",
    "    return nn.functional.mse_loss(x, x_recon)+1e1*nn.functional.mse_loss(x_enc, x_map)\n",
    "\n",
    "# Find the initial nn lists\n",
    "kd_tree_m = KDTree(model.GFN.mesh_m)\n",
    "nn_ns = [kd_tree_m.query(mesh, k=1)[1].astype('int') for mesh in meshes_train]\n",
    "nn_ms = [KDTree(mesh).query(model.GFN.mesh_m, k=1)[1].astype('int') for mesh in meshes_train]\n",
    "\n",
    "check_if_expanded = True\n",
    "# List to check if we need to agglomerate or expand\n",
    "need_agg = [True]*len(meshes_train)\n",
    "need_exp = [True]*len(meshes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a04e245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:06<00:25,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 10.480146408081055 | test loss: 10.106281280517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:12<00:19,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 10.1358060836792 | test loss: 10.276844024658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:19<00:12,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss: 10.232756614685059 | test loss: 10.152261734008789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:26<00:06,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train loss: 10.171481132507324 | test loss: 9.980958938598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:32<00:00,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train loss: 9.989314079284668 | test loss: 9.951906204223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    U_train = sols_train[0][train_trajs[0]]\n",
    "    params_train = params[train_trajs[0]]\n",
    "    n_expansions = 0\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for j in range(len(meshes_train)):\n",
    "        U_train = sols_train[j][train_trajs[j]]\n",
    "        params_train = params[train_trajs[j]]\n",
    "        mesh_n = meshes_train[j]\n",
    "        x_recon, x_enc, x_map, n_exp, n_agg = model(U_train, mesh_n, params_train, update_master=expand_master, nn_m=nn_ms[j], nn_n=nn_ns[j], expand=need_exp[j], agglomerate=need_agg[j])\n",
    "        \n",
    "        if check_if_expanded:\n",
    "            if n_exp == 0:\n",
    "                need_exp[j] = False\n",
    "            if n_agg == 0:\n",
    "                need_agg[j] = False\n",
    "        \n",
    "        n_expansions += n_exp\n",
    "        loss += criterion(U_train, x_recon, x_enc, x_map) * mesh_n.shape[0]\n",
    "        \n",
    "    if n_expansions > 0 and check_if_expanded and expand_master:\n",
    "        kd_tree_m = KDTree(model.GFN.mesh_m)\n",
    "        nn_ns = [kd_tree_m.query(mesh, k=1)[1].astype('int') for mesh in meshes_train]\n",
    "        nn_ms = [KDTree(mesh).query(model.GFN.mesh_m, k=1)[1].astype('int') for mesh in meshes_train]\n",
    "        need_agg = [True] * len(meshes_train)\n",
    "        need_exp = [True] * len(meshes_train)\n",
    "    else:\n",
    "        check_if_expanded = False\n",
    "    \n",
    "    loss /= np.sum([k.shape[0] for k in meshes_train])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        params_test = params[test_trajs]\n",
    "\n",
    "        for j in range(len(meshes_train)):\n",
    "            U_test = sols_train[j][test_trajs]\n",
    "            mesh_n = meshes_train[j]\n",
    "            \n",
    "            x_recon, x_enc, x_map, _, _ = model(U_test, mesh_n, params_test, update_master=expand_master, nn_m=nn_ms[j], nn_n=nn_ns[j], expand=need_exp[j], agglomerate=need_agg[j])\n",
    "            test_loss += criterion(U_test, x_recon, x_enc, x_map).item() * mesh_n.shape[0]\n",
    "        \n",
    "        test_loss /= np.sum([k.shape[0] for k in meshes_train])\n",
    "    \n",
    "    print(f'Epoch {i}: train loss: {train_loss} | test loss: {test_loss}')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    if test_loss<best_loss:\n",
    "        best_loss = test_loss\n",
    "        best_epoch = i\n",
    "        torch.save(model.state_dict(), save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e18431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc201167",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de28c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GFN_ROM(start_mesh, gfn_latent_size, latent_size, n_params, act, ae_sizes, mapper_sizes).to(dev)\n",
    "print(model.GFN.mesh_m.shape)\n",
    "\n",
    "# We do all of the possible expansions apriori in the preadaptive case\n",
    "# This is a preprocessing step so we don't do any speedup steps here\n",
    "if mode=='preadapt':\n",
    "    count = 0\n",
    "    while count!=0:\n",
    "        count = 0\n",
    "        for mesh_n in meshes_train:\n",
    "            n_exp, n_agg = model.GFN.reshape_weights(mesh_n, update_master=True)\n",
    "            count += n_exp\n",
    "    print(model.GFN.mesh_m.shape)\n",
    "    \n",
    "model.load_state_dict(torch.load(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9461ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model, mesh_n, U_large, scale, params):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_recon, x_enc, x_map, _, _ = model(U_large, mesh_n, params)\n",
    "        \n",
    "        x_rom = model.decoder(x_map)\n",
    "        x_rom = x_rom@model.GFN.Wd_n + model.GFN.bd_n\n",
    "\n",
    "        error_abs_list = list()\n",
    "        norm_z_list = list()\n",
    "        latents_error = list()\n",
    "        Z = undo_scaling(U_large, scale)\n",
    "        Z_net = undo_scaling(x_rom, scale)\n",
    "        for snap in range(U_large.shape[0]):\n",
    "            error_abs = np.linalg.norm(abs(Z[:, snap] - Z_net[:, snap]))\n",
    "            norm_z = np.linalg.norm(Z[:, snap], 2)\n",
    "            error_abs_list.append(error_abs)\n",
    "            norm_z_list.append(norm_z)\n",
    "            lat_err = np.linalg.norm(x_enc[snap] - x_map[snap])/np.linalg.norm(x_enc[snap])\n",
    "            latents_error.append(lat_err)\n",
    "\n",
    "        latents_error = np.array(latents_error)\n",
    "        print(\"\\nMaximum relative error for latent  = \", max(latents_error))\n",
    "        print(\"Mean relative error for latent = \", sum(latents_error)/len(latents_error))\n",
    "        print(\"Minimum relative error for latent = \", min(latents_error))\n",
    "\n",
    "        error = np.array(error_abs_list)\n",
    "        norm = np.array(norm_z_list)\n",
    "        rel_error = error/norm\n",
    "        print(\"\\nMaximum absolute error for field \"+\" = \", max(error))\n",
    "        print(\"Mean absolute error for field \"+\" = \", sum(error)/len(error))\n",
    "        print(\"Minimum absolute error for field \"+\" = \", min(error))\n",
    "        print(\"\\nMaximum relative error for field \"+\" = \", max(rel_error))\n",
    "        print(\"Mean relative error for field \"+\" = \", sum(rel_error)/len(rel_error))\n",
    "        print(\"Minimum relative error for field \"+\" = \", min(rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7c70583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "TEST MESH: reference_mesh_large.npy\n",
      "reconstruction error tensor(5.4842e-09, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.1077591\n",
      "Mean relative error for latent =  0.9745138394223019\n",
      "Minimum relative error for latent =  0.89683414\n",
      "\n",
      "Maximum absolute error for field  =  66.38595\n",
      "Mean absolute error for field  =  28.115018092773177\n",
      "Minimum absolute error for field  =  11.474413\n",
      "\n",
      "Maximum relative error for field  =  0.68864375\n",
      "Mean relative error for field  =  0.35845509556714783\n",
      "Minimum relative error for field  =  0.16659224\n",
      "\n",
      "----------------------------------------\n",
      "TEST MESH: reference_mesh.npy\n",
      "reconstruction error tensor(2.4297e-09, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.1068138\n",
      "Mean relative error for latent =  0.9744961149143901\n",
      "Minimum relative error for latent =  0.8963959\n",
      "\n",
      "Maximum absolute error for field  =  44.285637\n",
      "Mean absolute error for field  =  18.680929264561698\n",
      "Minimum absolute error for field  =  7.6297545\n",
      "\n",
      "Maximum relative error for field  =  0.68646663\n",
      "Mean relative error for field  =  0.35835087447511876\n",
      "Minimum relative error for field  =  0.1666003\n",
      "\n",
      "----------------------------------------\n",
      "TEST MESH: reference_mesh_small.npy\n",
      "reconstruction error tensor(6.2541e-10, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.0910069\n",
      "Mean relative error for latent =  0.977171438576823\n",
      "Minimum relative error for latent =  0.9031234\n",
      "\n",
      "Maximum absolute error for field  =  22.451439\n",
      "Mean absolute error for field  =  9.431618230925364\n",
      "Minimum absolute error for field  =  3.824009\n",
      "\n",
      "Maximum relative error for field  =  0.6875135\n",
      "Mean relative error for field  =  0.3586709332567724\n",
      "Minimum relative error for field  =  0.16631761\n",
      "\n",
      "----------------------------------------\n",
      "TEST MESH: reference_mesh_tiny.npy\n",
      "reconstruction error tensor(1.0880e-10, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.0917115\n",
      "Mean relative error for latent =  0.9837247633629225\n",
      "Minimum relative error for latent =  0.9142859\n",
      "\n",
      "Maximum absolute error for field  =  9.101887\n",
      "Mean absolute error for field  =  3.8178069561042567\n",
      "Minimum absolute error for field  =  1.56782\n",
      "\n",
      "Maximum relative error for field  =  0.6885813\n",
      "Mean relative error for field  =  0.35998135237869894\n",
      "Minimum relative error for field  =  0.16985062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_mesh_names)):\n",
    "    print('-'*40)\n",
    "    print(f'TEST MESH: {test_mesh_names[i]}')\n",
    "    scale, U = get_scaled_data(test_solution_names[i])\n",
    "    U = U.to('cpu')\n",
    "    df = np.load(test_mesh_names[i])\n",
    "\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    with torch.no_grad():\n",
    "        print_results(model, df, U, scale, params.to('cpu'))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
