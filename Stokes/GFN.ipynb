{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'stokes'\n",
    "n_params = 7\n",
    "\n",
    "# NB: order training meshes by largest first\n",
    "train_mesh_names = ['reference_mesh.csv', 'reference_mesh_small.csv', 'reference_mesh_tiny.csv']\n",
    "train_solution_names = ['matrix.mat', 'matrix_small.mat', 'matrix_tiny.mat']\n",
    "\n",
    "test_mesh_names = ['reference_mesh_large.csv', 'reference_mesh.csv', 'reference_mesh_small.csv', 'reference_mesh_tiny.csv']\n",
    "test_solution_names = ['matrix_large.mat', 'matrix.mat', 'matrix_small.mat', 'matrix_tiny.mat']\n",
    "\n",
    "save_name = 'best_model_sm.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc115edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pykdtree.kdtree import KDTree\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c6b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9f867",
   "metadata": {},
   "source": [
    "## THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60269142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFN_AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Module implementing the GFN method for the encoder and decoder architectures.\n",
    "    Methods:\n",
    "    __init__: initialises the master mesh, and master weight & biases for the 1st and last layer of the encoder and decoder, respectively\n",
    "    expand: add all new expansive nodes in the new mesh to the weight matrices\n",
    "    agglomerate: agglomerate nodes to fit the new mesh\n",
    "    encoder: execute the encoder part\n",
    "    decoder: execute the decoder part\n",
    "    \"\"\"\n",
    "    def __init__(self, mesh_m, latent_size=20):\n",
    "        super().__init__()\n",
    "        size = mesh_m.shape[0]\n",
    "        self.latent_size = latent_size\n",
    "        self.We_m = nn.Parameter(torch.empty(size, self.latent_size))\n",
    "        self.be_m = nn.Parameter(torch.empty(self.latent_size))\n",
    "        self.Wd_m = nn.Parameter(torch.empty(self.latent_size, size))\n",
    "        self.bd_m = nn.Parameter(torch.empty(size))\n",
    "        self.mesh_m = mesh_m\n",
    "        \n",
    "        self.initialise(self.We_m, self.be_m)\n",
    "        self.initialise(self.Wd_m, self.bd_m)\n",
    "        \n",
    "        # Note: no self.be_n since we never need to reshape the encoder biases i.e. be_n == be_m in all cases\n",
    "        self.We_n = self.We_m.clone()\n",
    "        self.Wd_n = self.Wd_m.clone()\n",
    "        self.bd_n = self.bd_m.clone()\n",
    "        self.mesh_n = self.mesh_m\n",
    "        \n",
    "    def initialise(self, weight, bias):\n",
    "        stdv = 1. / math.sqrt(weight.size(1))\n",
    "        weight.data.uniform_(-stdv, stdv)\n",
    "        bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def expand(self, mesh_n, kd_tree_m=None, kd_tree_n=None, nn_m=None, nn_n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Expand the new weights and biases with the new expansive nodes. If during training, update the master weights, biases & mesh.\n",
    "        If during inference, then just apply the new ones.\n",
    "        \"\"\"\n",
    "        \n",
    "        # During evaluation, we will have fixed mesh_m so we don't want to recompute every time => option to pass in\n",
    "        if nn_n is not None:\n",
    "            pass\n",
    "        elif kd_tree_n is not None:\n",
    "            nn_n = kd_tree_m.query(mesh_n, k=1)[1]\n",
    "        else:\n",
    "            kd_tree_m = KDTree(self.mesh_m)\n",
    "            nn_n = kd_tree_m.query(mesh_n, k=1)[1]\n",
    "        # During training, we will have fixed fidelities that we know and don't need to always recompute\n",
    "        if nn_m is not None:\n",
    "            pass\n",
    "        elif kd_tree_n is not None:\n",
    "            nn_m = kd_tree_n.query(self.mesh_m, k=1)[1]\n",
    "        else:\n",
    "            kd_tree_n = KDTree(mesh_n)\n",
    "            nn_m = kd_tree_n.query(self.mesh_m, k=1)[1]\n",
    "\n",
    "        if not self.training:\n",
    "            # ! testing mode !\n",
    "            \n",
    "            # could assign with .data calls here but can't do for train https://discuss.pytorch.org/t/function-tbackward-returned-an-invalid-gradient-at-index-0-got-1-3-but-expected-shape-compatible-with-1-2/125259\n",
    "            \n",
    "            count_m = np.zeros(self.mesh_m.shape[0]) # track how many neighbours\n",
    "            nodes_added = 0 # how much did we increase our master mesh\n",
    "\n",
    "            for pt_n, pt_m in enumerate(nn_n):\n",
    "                if nn_m[pt_m]!=pt_n: # if not bidirectional link <->\n",
    "                    nodes_added += 1\n",
    "                    self.mesh_n = np.vstack([self.mesh_n, mesh_n[pt_n]])\n",
    "                    count_m[pt_m]+=1\n",
    "\n",
    "                    # Divide encoder weights by number of expansions\n",
    "                    self.We_n[pt_m]*=count_m[pt_m]/(count_m[pt_m]+1)\n",
    "                    # Store the index of the weight we want\n",
    "                    # so we can update at the end without storing\n",
    "                    # all the nodes to update explictly\n",
    "                    new_row = torch.zeros(1, self.We_n.shape[1])\n",
    "                    new_row[0][0] = pt_m\n",
    "                    self.We_n = torch.cat((self.We_n, new_row), dim=0)\n",
    "\n",
    "                    # Duplicate weights for decoder\n",
    "                    self.Wd_n = torch.cat((self.Wd_n, self.Wd_n[:, pt_m:pt_m+1]), dim=1)\n",
    "                    self.bd_n = torch.cat([self.bd_n, self.bd_n[pt_m:pt_m+1]])\n",
    "\n",
    "            # Loop over the nodes we need to update using the index we stored in the first element\n",
    "            for i in range(self.mesh_m.shape[0], self.mesh_m.shape[0]+nodes_added):\n",
    "                index = int(self.We_n[i,0])\n",
    "                self.We_n[i] = self.We_n[index]\n",
    "        else:\n",
    "            # ! training mode !\n",
    "            \n",
    "            # Expansion step is essentially creating new weights from scratch\n",
    "            # => ignore gradients and therefore allow for slicing on leaf tensor as required\n",
    "            # (Unless we do something smarter with the gradient tree to track what we're doing...)\n",
    "            with torch.no_grad():\n",
    "                count_m = np.zeros(self.mesh_m.shape[0]) # track how many neighbours\n",
    "                nodes_added = 0 # how much did we increase our master mesh\n",
    "                size=self.mesh_m.shape[0]\n",
    "\n",
    "                for pt_n, pt_m in enumerate(nn_n):\n",
    "                    if nn_m[pt_m]!=pt_n: # if not bidirectional link <->\n",
    "                        nodes_added += 1\n",
    "                        self.mesh_m=np.vstack([self.mesh_m, mesh_n[pt_n]])\n",
    "                        count_m[pt_m]+=1\n",
    "                        \n",
    "                        # Divide encoder weights by number of expansions\n",
    "                        self.We_m[pt_m]*=count_m[pt_m]/(count_m[pt_m]+1)\n",
    "                        # Store the index of the weight we want\n",
    "                        # so we can update at the end without storing\n",
    "                        # all the nodes to update explictly\n",
    "                        new_row = torch.zeros(1, self.We_m.shape[1])\n",
    "                        new_row[0][0] = pt_m\n",
    "                        self.We_m = nn.Parameter(torch.cat((self.We_m, new_row), dim=0))\n",
    "                        \n",
    "                        # Duplicate weights for decoder\n",
    "                        self.Wd_m = nn.Parameter(torch.cat((self.Wd_m, self.Wd_m[:, pt_m:pt_m+1]), dim=1))\n",
    "                        self.bd_m = nn.Parameter(torch.cat([self.bd_m, self.bd_m[pt_m:pt_m+1]]))\n",
    "                \n",
    "                # Loop over the nodes we need to update using the index we stored in the first element\n",
    "                for i in range(size, size+nodes_added):\n",
    "                    index = int(self.We_m[i,0])\n",
    "                    self.We_m[i] = self.We_m[index]\n",
    "            \n",
    "            # now we need to track gradients from our new master weights\n",
    "            self.We_n = self.We_m.clone()\n",
    "            self.Wd_n = self.Wd_m.clone()\n",
    "            self.bd_n = self.bd_m.clone()\n",
    "        return nodes_added\n",
    "        \n",
    "    def agglomerate(self, mesh_n, kd_tree_n=None, nn_m=None, **kwargs):\n",
    "        \n",
    "        # known during training\n",
    "        if nn_m is not None:\n",
    "            pass\n",
    "        # already found in expansion or already known during training\n",
    "        elif kd_tree_n is not None:\n",
    "            nn_m = kd_tree_n.query(self.mesh_n, k=1)[1]\n",
    "        else:\n",
    "            kd_tree_n = KDTree(mesh_n)\n",
    "            nn_m = kd_tree_n.query(self.mesh_n, k=1)[1]\n",
    "\n",
    "        # FIND NEW WEIGHTS (AGGLOMERATIVE ONLY NOW)\n",
    "        We_n = torch.zeros((mesh_n.shape[0], self.We_n.shape[1]), device=self.We_n.device)\n",
    "        Wd_n = torch.zeros((self.We_n.shape[1], mesh_n.shape[0]), device=self.We_n.device)\n",
    "        bd_n = torch.zeros(mesh_n.shape[0], device=self.We_n.device)\n",
    "\n",
    "        count_n = np.zeros(mesh_n.shape[0])\n",
    "\n",
    "        for m, pt_m in enumerate(self.mesh_n): # agglomerate\n",
    "            nn_n = nn_m[m]\n",
    "            count_n[nn_n]+=1\n",
    "            We_n[nn_n] += self.We_n[m]\n",
    "            Wd_n[:, nn_n] = ( (count_n[nn_n]-1)*Wd_n[:, nn_n] + self.Wd_n[:, m] )/count_n[nn_n]\n",
    "            bd_n[nn_n] = ( (count_n[nn_n]-1)*bd_n[nn_n] + self.bd_n[m] )/count_n[nn_n]\n",
    "          \n",
    "        self.We_n = We_n\n",
    "        self.Wd_n = Wd_n\n",
    "        self.bd_n = bd_n\n",
    "        \n",
    "    def reset(self):\n",
    "        self.We_n = self.We_m.clone()\n",
    "        self.Wd_n = self.Wd_m.clone()\n",
    "        self.bd_n = self.bd_m.clone()\n",
    "        if not self.training:\n",
    "            self.mesh_n = self.mesh_m\n",
    "        \n",
    "    def encoder(self, x, mesh_n, exp_enc=True, agg_enc=True, reset_enc=False, **kwargs):\n",
    "        if reset_enc:\n",
    "            self.reset()\n",
    "        if exp_enc:\n",
    "            self.expand(mesh_n, **kwargs)\n",
    "        if agg_enc:\n",
    "            self.agglomerate(mesh_n, **kwargs)\n",
    "        return x@self.We_n+self.be_m\n",
    "        \n",
    "    def decoder(self, x, mesh_n, exp_dec=True, agg_dec=True, reset_dec=False, **kwargs):\n",
    "        if reset_dec:\n",
    "            self.reset()\n",
    "        if exp_dec:\n",
    "            self.expand(mesh_n, **kwargs)\n",
    "        if agg_dec:\n",
    "            self.agglomerate(mesh_n, **kwargs)\n",
    "        return x@self.Wd_n+self.bd_n\n",
    "    \n",
    "class GCA(nn.Module):\n",
    "    \n",
    "    def __init__(self, mesh_m, gfn_latent_size=20, latent_size=20, n_params=7, act=nn.Tanh, ae_sizes=[], map_sizes=[50]*4):\n",
    "        super().__init__()\n",
    "        self.GFN = GFN_AE(mesh_m, gfn_latent_size)\n",
    "        \n",
    "        self.act = act()\n",
    "        \n",
    "        module_list_enc = []\n",
    "        module_list_dec = []\n",
    "\n",
    "        for i in range(len(ae_sizes)):\n",
    "            module_list_dec.append(self.act)\n",
    "            if i==0:\n",
    "                module_list_enc.append(nn.Linear(gfn_latent_size, ae_sizes[i]))\n",
    "                module_list_dec.append(nn.Linear(ae_sizes[i], gfn_latent_size))\n",
    "            else:\n",
    "                module_list_enc.append(nn.Linear(ae_sizes[i-1], ae_sizes[i]))\n",
    "                module_list_dec.append(nn.Linear(ae_sizes[i], ae_sizes[i-1]))\n",
    "            module_list_enc.append(self.act)\n",
    "        if len(ae_sizes)!=0:\n",
    "            module_list_dec.append(self.act)\n",
    "            module_list_enc.append(nn.Linear(ae_sizes[-1], latent_size))\n",
    "            module_list_dec.append(nn.Linear(latent_size, ae_sizes[-1]))\n",
    "            module_list_enc.append(self.act)\n",
    "        \n",
    "        self.encoder = nn.Sequential(*module_list_enc)\n",
    "        self.decoder = nn.Sequential(*module_list_dec[::-1])\n",
    "        \n",
    "        module_list_map = []\n",
    "        \n",
    "        for i in range(len(map_sizes)):\n",
    "            if i==0:\n",
    "                module_list_map.append(nn.Linear(n_params, map_sizes[i]))\n",
    "            else:\n",
    "                module_list_map.append(nn.Linear(map_sizes[i-1], map_sizes[i]))\n",
    "            module_list_map.append(act())\n",
    "        if len(map_sizes)!=0:\n",
    "            module_list_map.append(nn.Linear(map_sizes[-1], latent_size))\n",
    "            \n",
    "        self.mapper = nn.Sequential(*module_list_map)\n",
    "        \n",
    "    def forward(self, x, mesh_n, params, **kwargs):\n",
    "        x_enc = self.act(self.GFN.encoder(x, mesh_n, **kwargs))\n",
    "        x_enc = self.encoder(x_enc)\n",
    "        \n",
    "        x_map = self.mapper(params)\n",
    "        \n",
    "        x_recon = self.decoder(x_enc)\n",
    "        x_recon = self.GFN.decoder(x_enc, mesh_n, **kwargs)\n",
    "        \n",
    "        return x_recon, x_enc, x_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b67f68",
   "metadata": {},
   "source": [
    "## SET UP TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826652a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_params(pname='stokes'):\n",
    "    if pname=='stokes':\n",
    "        mu_range = [(0.5,1.5), (0.5,1.5), (0.5,1.5), (0.5,1.5), (0.5,1.5), (-np.pi/6,np.pi/6), (-10,10)]\n",
    "        mus = []\n",
    "        n_pts = [2]*(len(mu_range)-1)+[11]\n",
    "        for i in range(len(mu_range)):\n",
    "            mus.append(np.linspace(mu_range[i][0], mu_range[i][1], n_pts[i]))\n",
    "        return torch.tensor(np.array(list(product(*mus)))).float()\n",
    "    elif pname=='graetz':\n",
    "        mus = [np.linspace(1., 3., 10), np.linspace(0.01, 0.1, 20)]\n",
    "        mu1, mu2 = np.meshgrid(mus[0], mus[1])\n",
    "        return torch.tensor(np.vstack((mu1.T, mu2.T)).reshape(2, -1).T).float()\n",
    "    elif pname=='advection':\n",
    "        mus = [np.linspace(0., 6., 10), np.linspace(-1.0, 1.0, 10)]\n",
    "        mu1, mu2 = np.meshgrid(mus[0], mus[1])\n",
    "        return torch.tensor(np.vstack((mu1.T, mu2.T)).reshape(2, -1).T).float()\n",
    "\n",
    "def scaler_func():\n",
    "    return preprocessing.StandardScaler()\n",
    "\n",
    "def scaling(U):\n",
    "    scaling_fun_1 = scaler_func()\n",
    "    scaling_fun_2 = scaler_func()\n",
    "    scaler_s = scaling_fun_1.fit(U)\n",
    "    temp = torch.t(torch.tensor(scaler_s.transform(U)))\n",
    "    scaler_f = scaling_fun_2.fit(temp)\n",
    "    scaled_data = torch.unsqueeze(torch.t(torch.tensor(scaler_f.transform(temp))),0).permute(2, 1, 0)\n",
    "    scale = [scaler_s, scaler_f]\n",
    "    return scale, scaled_data[:,:,0]\n",
    "\n",
    "def undo_scaling(U, scale):\n",
    "    scaler_s = scale[0]\n",
    "    scaler_f = scale[1]\n",
    "    rescaled_data = torch.tensor(scaler_s.inverse_transform(torch.t(torch.tensor(scaler_f.inverse_transform(U.detach().numpy().squeeze())))))\n",
    "    return rescaled_data\n",
    "\n",
    "def get_scaled_data(fname):\n",
    "    U_orig = torch.tensor(scipy.io.loadmat(fname)['U'])\n",
    "    scale, U_sc = scaling(U_orig)\n",
    "    print('reconstruction error', ((U_orig - undo_scaling(U_sc, scale))**2).sum())\n",
    "    return scale, U_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error tensor(4.0544e-27, dtype=torch.float64)\n",
      "reconstruction error tensor(1.0720e-27, dtype=torch.float64)\n",
      "reconstruction error tensor(2.1232e-28, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "params = get_params(pname).to(dev)\n",
    "\n",
    "dfs_train = [pd.read_csv(i, header=None).values for i in train_mesh_names]\n",
    "\n",
    "sols_train = [get_scaled_data(i)[1].float().to(dev) for i in train_solution_names]\n",
    "\n",
    "trajs = list(range(sols_train[0].shape[0]))\n",
    "random.shuffle(trajs)\n",
    "train_trajs, test_trajs = np.array_split(trajs, 2)\n",
    "train_trajs = np.array_split(train_trajs, len(dfs_train))\n",
    "\n",
    "# train_trajs = random.sample(range(704), 352)\n",
    "# test_trajs =list(set(range(704))-set(train_trajs))\n",
    "# train_trajs=[train_trajs[176:], train_trajs[:176]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6adfe",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2617c35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialisation\n",
    "# NB - important to start with largest mesh since this is better for initialisation purposes\n",
    "# and potential savings in no expansions are done\n",
    "model = GCA(dfs_train[0]).to(dev)\n",
    "\n",
    "# conduct the expansion step\n",
    "added_nodes = 0\n",
    "for df in dfs_train[1:]:\n",
    "    added_nodes += model.GFN.expand(df)\n",
    "\n",
    "added_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306f588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5432f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "# now initialise our optimiser after we have conducted ALL expansions\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091eeae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:18,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 10.192414283752441 | test loss: 8.047617745411031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:09<00:13,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 9.589112281799316 | test loss: 7.783030015776242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:13<00:09,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss: 9.294427871704102 | test loss: 7.5501771058726534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:18<00:04,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train loss: 8.957832336425781 | test loss: 7.22350989021379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train loss: 8.568116188049316 | test loss: 6.950985881234048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "EPOCHS = 5#000\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "\n",
    "def criterion(x, x_recon, x_enc, x_map):\n",
    "    return nn.functional.mse_loss(x, x_recon)+1e1*nn.functional.mse_loss(x_enc, x_map)\n",
    "\n",
    "kd_tree_m = KDTree(model.GFN.mesh_m)\n",
    "# we know ahead of time the nn_n and nn_ms since we know that the master mesh is never changing and our new meshes are fixed\n",
    "nn_ns = [kd_tree_m.query(df, k=1)[1] for df in dfs_train]\n",
    "nn_ms = [KDTree(df).query(model.GFN.mesh_m, k=1)[1] for df in dfs_train]\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    U_train = sols_train[0][train_trajs[0]]\n",
    "    params_train = params[train_trajs[0]]\n",
    "    df_train = dfs_train[0]\n",
    "    if added_nodes==0:\n",
    "        # because added_nodes==0, we know we don't need to expand or agglom for the medium mesh\n",
    "        x_recon, x_enc, x_map = model(U_train, df_train, params_train, exp_enc=False, exp_dec=False, agg_enc=False, agg_dec=False, reset_enc=True)\n",
    "    else:\n",
    "        # NEED TO TEST\n",
    "        # we need to agglomerate because added_nodes>0. However, we do this all in the encoder first so we can avoid in the decoder\n",
    "        x_recon, x_enc, x_map = model(U_train, df_train, params_train, exp_enc=False, exp_dec=False, agg_dec=False, reset_enc=True, nn_n=nn_ns[0], nn_m=nn_ms[0])\n",
    "\n",
    "    loss = criterion(U_train, x_recon, x_enc, x_map)*df_train.shape[0]\n",
    "\n",
    "    # other fidelities\n",
    "    for j in range(1, len(dfs_train)):\n",
    "        U_train = sols_train[j][train_trajs[j]]\n",
    "        params_train = params[train_trajs[j]]\n",
    "        df_train = dfs_train[j]\n",
    "        \n",
    "        # only need to agglom in training since we expanded as a preprocessing step\n",
    "        x_recon, x_enc, x_map = model(U_train, df_train, params_train, exp_enc=False, exp_dec=False, agg_dec=False, reset_enc=True, nn_m=nn_ms[j], nn_n=nn_ns[j])\n",
    "        loss += criterion(U_train, x_recon, x_enc, x_map)*df_train.shape[0]\n",
    "    \n",
    "    loss /= np.sum([k.shape[0] for k in dfs_train])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        params_test = params[test_trajs]\n",
    "        \n",
    "        U_test = sols_train[0][test_trajs]\n",
    "        df_test = dfs_train[0]\n",
    "\n",
    "        if added_nodes==0:\n",
    "            x_recon, x_enc, x_map = model(U_test, df_test, params_test, exp_enc=False, exp_dec=False, agg_enc=False, agg_dec=False, reset_enc=True)\n",
    "        else:\n",
    "            x_recon, x_enc, x_map = model(U_test, df_test, params_test, exp_enc=False, exp_dec=False, agg_dec=False, reset_enc=True, nn_n=nn_ns[0], nn_m=nn_ms[0])\n",
    "        test_loss = criterion(U_test, x_recon, x_enc, x_map).item()*df_test.shape[0]\n",
    "\n",
    "        for j in range(1, len(dfs_train)):\n",
    "            U_test = sols_train[j][test_trajs]\n",
    "            df_test = dfs_train[j]\n",
    "            \n",
    "            # only need to agglom in training since we expanded as a preprocessing step\n",
    "            x_recon, x_enc, x_map = model(U_test, df_test, params_test, exp_enc=False, exp_dec=False, agg_dec=False, reset_enc=True, nn_m=nn_ms[j], nn_n=nn_ns[j])\n",
    "            test_loss += criterion(U_test, x_recon, x_enc, x_map).item()*df_train.shape[0]\n",
    "        \n",
    "        test_loss /= np.sum([k.shape[0] for k in dfs_train])\n",
    "    \n",
    "    print(f'Epoch {i}: train loss: {train_loss} | test loss: {test_loss}')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    if test_loss<best_loss:\n",
    "        best_loss=test_loss\n",
    "        best_epoch = i\n",
    "        torch.save(model.state_dict(), save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adf1f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCA(dfs_train[0]).to(dev)\n",
    "\n",
    "# conduct the expansion step\n",
    "added_nodes = 0\n",
    "for df in dfs_train[1:]:\n",
    "    added_nodes += model.GFN.expand(df)\n",
    "\n",
    "model.load_state_dict(torch.load(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984248e4",
   "metadata": {},
   "source": [
    "## EVALUATE PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721713de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model, df_large, U_large, scale, params):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_recon, x_enc, x_map = model(U_large, df_large, params, reset_enc=True, reset_dec=True)\n",
    "        \n",
    "        x_rom = model.decoder(x_map)\n",
    "        x_rom = model.GFN.decoder(x_rom, df_large, exp_enc=False, exp_dec=False, agg_enc=False, agg_dec=False)\n",
    "\n",
    "        error_abs_list = list()\n",
    "        norm_z_list = list()\n",
    "        latents_error = list()\n",
    "        Z = undo_scaling(U_large, scale)\n",
    "        Z_net = undo_scaling(x_rom, scale)\n",
    "        for snap in range(U_large.shape[0]):\n",
    "            error_abs = np.linalg.norm(abs(Z[:, snap] - Z_net[:, snap]))\n",
    "            norm_z = np.linalg.norm(Z[:, snap], 2)\n",
    "            error_abs_list.append(error_abs)\n",
    "            norm_z_list.append(norm_z)\n",
    "            lat_err = np.linalg.norm(x_enc[snap] - x_map[snap])/np.linalg.norm(x_enc[snap])\n",
    "            latents_error.append(lat_err)\n",
    "\n",
    "        latents_error = np.array(latents_error)\n",
    "        print(\"\\nMaximum relative error for latent  = \", max(latents_error))\n",
    "        print(\"Mean relative error for latent = \", sum(latents_error)/len(latents_error))\n",
    "        print(\"Minimum relative error for latent = \", min(latents_error))\n",
    "\n",
    "        error = np.array(error_abs_list)\n",
    "        norm = np.array(norm_z_list)\n",
    "        rel_error = error/norm\n",
    "        print(\"\\nMaximum absolute error for field \"+\" = \", max(error))\n",
    "        print(\"Mean absolute error for field \"+\" = \", sum(error)/len(error))\n",
    "        print(\"Minimum absolute error for field \"+\" = \", min(error))\n",
    "        print(\"\\nMaximum relative error for field \"+\" = \", max(rel_error))\n",
    "        print(\"Mean relative error for field \"+\" = \", sum(rel_error)/len(rel_error))\n",
    "        print(\"Minimum relative error for field \"+\" = \", min(rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c32539b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAGwCAYAAABiu4tnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVKUlEQVR4nO3de1xUdf4/8NfMwHC/34c7ggiiqCjkLUBNJcO8tLXat6Xaamutzdxq3d/uVlvb/WYla/Vdy7K+m900K+/KpZTEK4oXEERE7ojc7zPn98fBmUa8MQLnDLyej8c8HnHOZ2beh1mc137O57yPQhAEAURERETUa0qpCyAiIiIyVwxSRERERCZikCIiIiIyEYMUERERkYkYpIiIiIhMxCBFREREZCIGKSIiIiITWUhdwGCm0+lQVlYGBwcHKBQKqcshIiKi6yAIAhobG6HRaKBUXn3OiUGqH5WVlcHf31/qMoiIiMgEJSUl8PPzu+oYBql+5ODgAED8IBwdHSWuhoiIiK5HQ0MD/P399d/jV8Mg1Y8uns5zdHRkkCIiIjIz17Msh4vNiYiIiEzEIEVERERkIgYpIiIiIhNxjRQREZGZ0mq16OzslLoMs2NpaQmVStUnr8UgRUREZGYEQUBFRQXq6uqkLsVsOTs7w9vb+4b7PDJIERERmZmLIcrT0xO2trZs+twLgiCgpaUFVVVVAAAfH58bej0GKSIiIjOi1Wr1IcrNzU3qcsySjY0NAKCqqgqenp43dJqPi82JiIjMyMU1Uba2thJXYt4u/v5udI0ZgxQREZEZ4um8G9NXvz8GKSIiIiITMUgRERERmYhBioiIiMxOUFAQVqxYIXUZvGrPXP10qhoTQ9xgoWIWJiIi85CQkIAxY8b0SQDat28f7OzsbryoG8QgZYaOnKvDPauzEeBqiz/Eh2DhOD9YW/ZNh1YiIiKpCIIArVYLC4trxxMPD48BqOjaOJ1hhsrqWuFqp8bZ2hb8bX0upr6Whg8zC9HU3iV1aURENMAEQUBLR5ckD0EQrrvOe++9FxkZGXjnnXegUCigUCiwZs0aKBQKbN68GTExMbCyssLPP/+MwsJC3H777fDy8oK9vT0mTJiAHTt2GL3epaf2FAoF/vOf/2D+/PmwtbVFWFgYNm7c2Fe/5ivijJQZmh3lg5uHe2DdvhJ8mHka5fVteGnTSaSmFSJlUhDumxQEFzu11GUSEdEAaO3UIvKZrZK89/HnZ8FWfX1R4p133kF+fj6ioqLw/PPPAwCOHTsGAFi+fDneeOMNhISEwMXFBSUlJbj11lvx4osvwsrKCp9++imSk5ORl5eHgICAK77HP//5T7z22mt4/fXX8d577+Huu+9GcXExXF1db/xgr4AzUmbKVm2B+yYHI+OpRLy2cDRC3O1Q39qJd3eewuRXd+FfPxxHRX2b1GUSEREBAJycnKBWq2Frawtvb294e3vrO4o///zzuOWWWzBs2DC4uroiOjoaf/jDHxAVFYWwsDC88MILGDZs2DVnmO69914sWrQIoaGheOmll9DU1ITs7Ox+PS7OSJk5tYUSd07wx8IYP2zJrUBqWgGOlzfgPz8X4dOsYiyM8cUfbh6GIHfpF+QREVHfs7FU4fjzsyR7774wfvx4o5+bmprw3HPP4ccff0R5eTm6urrQ2tqKs2fPXvV1Ro8erf9vOzs7ODo66u+p118YpAYJlVKBOaN9cOsob2TkV+PfaYXIPlOL/2aXYN2+EswZrcEfE4YhwsdR6lKJiKgPKRSK6z69JleXXn335JNPYvv27XjjjTcQGhoKGxsb3HHHHejo6Ljq61haWhr9rFAooNPp+rzeXzPv3zz1oFAokBDuiYRwT+w7U4t/pxUgLa8a3+eU4fucMkwb4YklicMQE9h/54uJiIguR61WQ6vVXnPc7t27ce+992L+/PkAxBmqM2fO9HN1puEaqUFsQpArPr4vFj/+aQpuG+0DhQLYdbIKC1dl4a4PspCRX92rKy6IiIhuRFBQEPbu3YszZ86gpqbmirNFYWFh+Pbbb3H48GHk5ORg8eLF/T6zZCoGqSFgpMYJKxePw64/J+C3E/xhqVJgb1EtUj7KRvLKn7H5aDl0OgYqIiLqX08++SRUKhUiIyPh4eFxxTVPb731FlxcXDBp0iQkJydj1qxZGDdu3ABXe30UAqck+k1DQwOcnJxQX18PR0f5rE0qr2/F/2YW4b/ZZ9HaKU6xhnjY4ZH4YZg31heW7JZORCRbbW1tKCoqQnBwMKytraUux2xd7ffYm+9vfmMOQT5ONngmORK7l0/Dn6aFwtHaAqerm/HU10cQ/1oa1uwuQmvHtc9hExERDXUMUkOYq50ay2aGY/fyafhr0gi421uhrL4Nz31/HFNe3YXUtALUt3ZKXSYREZFsMUhdw/z58+Hi4oI77rhD6lL6jYO1Jf4QPww//yURL8yLgp+LDc43d+D1rXmY8souvLblJGqa2qUuk4iISHYYpK7h8ccfx6effip1GQPC2lKFe24KRPqTCXj7rmgM97JHY3sX/p1eiMmv7MKz3+Xi3IUWqcskIiKSDQapa0hISICDg4PUZQwoC5US88f6YcvjN+PDe2IQ7e+M9i4dPskqRsLr6fjzlzkoqGqUukwiIiLJDeoglZmZieTkZGg0GigUCmzYsKHHmNTUVAQFBcHa2hpxcXH9fk8ec6JUKjBzpDc2/HESPn8gDpND3dClE/DNwXO45e1MPLz2AI6cq5O6TCIiIskM6iDV3NyM6OhopKamXnb/unXrsGzZMjz77LM4ePAgoqOjMWvWrH6/L4+5USgUmBzqjs8fuAkblkzGzEgvCAKw5VgF5q7cjXtW70VW4Xk29yQioiFnUN8iJikpCUlJSVfc/9Zbb+HBBx/EfffdBwB4//338eOPP+Kjjz7C8uXLe/1+7e3taG83LMpuaGjofdEyN8bfGR/+bjzyKxuxKr0QG3PK8NOpGvx0qgbjApyxJDEU00Z4QqFQSF0qERFRvxvUM1JX09HRgQMHDmDGjBn6bUqlEjNmzEBWVpZJr/nyyy/DyclJ//D39++rcmVnuJcD3r5rDNKfTMD/3BQAtYUSB8/W4fef7EfSOz/hu8Ol6NLKs50/ERFRXxmyQaqmpgZarRZeXl5G2728vFBRUaH/ecaMGfjNb36DTZs2wc/P76oh669//Svq6+v1j5KSkn6rXy78XW3xr3mj8PNfEvGH+BDYqVU4WdGIx784jOlvZeD/9p5FexebexIRkXgB19KlS/vs9e69917Mmzevz17PFIP61F5f2LFjx3WPtbKygpWVVT9WI1+eDtb4a1IE/hgfik+yzuDj3UUoPt+C/7f+KN7ZmY8HpoRgcVwA7Kz4PzkiIho8huyMlLu7O1QqFSorK422V1ZWwtvbW6KqzJ+TrSX+ND0Mu5dPwz9ui4S3ozUqG9rx4qYTmPzqLqzYkY+6lg6pyyQiogF27733IiMjA++88w4UCgUUCgXOnDmD3NxcJCUlwd7eHl5eXrjnnntQU1Ojf97XX3+NUaNGwcbGBm5ubpgxYwaam5vx3HPP4ZNPPsF3332nf7309PQBP64hG6TUajViYmKwc+dO/TadToedO3di4sSJElY2ONiqLfD7KcHIeDoBry4chSA3W9S1dGLFjlOY9MouvPjjcVQ2tEldJhGR+RMEoKNZmkcvrtZ+5513MHHiRDz44IMoLy9HeXk5HBwcMG3aNIwdOxb79+/Hli1bUFlZiTvvvBMAUF5ejkWLFuH+++/HiRMnkJ6ejgULFkAQBDz55JO48847MXv2bP3rTZo0qb9+y1c0qM+zNDU1oaCgQP9zUVERDh8+DFdXVwQEBGDZsmVISUnB+PHjERsbixUrVqC5uVl/FR/dOCsLFe6aEIA7YvyxObccqWmFOFHegP/9qQif7CnGwhg/PBwfgkA3O6lLJSIyT50twEsaad77/5UB6uv799vJyQlqtRq2trb6Mz//+te/MHbsWLz00kv6cR999BH8/f2Rn5+PpqYmdHV1YcGCBQgMDAQAjBo1Sj/WxsYG7e3tkp5JGtRBav/+/UhMTNT/vGzZMgBASkoK1qxZg7vuugvV1dV45plnUFFRgTFjxmDLli09FqDTjVMpFbhttAZzRvkgPb8aqbsKsL/4Av6bfRbr9p3FbaM1+GPiMIzwdpS6VCIiGiA5OTlIS0uDvb19j32FhYWYOXMmpk+fjlGjRmHWrFmYOXMm7rjjDri4uEhQ7eUpBHZR7DcNDQ1wcnJCfX09HB0ZEC6VXVSL1LQCZORX67fNiPDEIwmhiAmUzx8JEZGctLW1oaioCMHBwbC2thZPr3VKdB9US1ugF30DExISMGbMGKxYsQKA2O/R1tYWr776ao+xPj4+sLOzgyAI2LNnD7Zt24b169ejoqICe/fuRXBwMO69917U1dVd9s4l19Lj9/grvfn+HtQzUiRvscGuiA2ORW5pPValF2JTbjl2nKjCjhNVuCnEFUsSQzEl1J3NPYmIrkahuO7Ta1JTq9XQag0tccaNG4dvvvkGQUFBsLC4fCRRKBSYPHkyJk+ejGeeeQaBgYFYv349li1b1uP1pDBkF5uTfET5OiH17nHYsSwed473g4VSgV9O1+Ke1dmYu3I3tuSWQ6fjxCkRkbkLCgrC3r17cebMGdTU1GDJkiWora3FokWLsG/fPhQWFmLr1q247777oNVqsXfvXrz00kvYv38/zp49i2+//RbV1dWIiIjQv96RI0eQl5eHmpoadHZ2DvgxMUiRbAzzsMdrd0Qj8+lE3Dc5CNaWShwtrcfDnx3EzBWZ+PrAOXSyWzoRkdl68sknoVKpEBkZCQ8PD3R0dGD37t3QarWYOXMmRo0ahaVLl8LZ2RlKpRKOjo7IzMzErbfeiuHDh+Pvf/873nzzTf3t3x588EGEh4dj/Pjx8PDwwO7duwf8mLhGqh9xjdSNOd/Ujo93n8EnWWfQ2NYFAPB1tsFDN4fgrgn+sLZUSVwhEdHAu9raHrp+fbVGijNSJFtu9lZ4clY49iyfhr/MHgF3ezVK61rx7MZjmPLqLvw7vQANbQM/jUtERHQRgxTJnoO1JR5JGIaf/zINL9w+Er7ONqhp6sBrW/Iw+eVdeH3rSdQ0tUtdJhERDUEMUmQ2rC1VuGdiENKfSsBbd0Yj1NMeje1dSE0rxJRXd+G5jcdQWtcqdZlERDSEMEiR2bFUKbFgnB+2Lb0ZH9wTg9F+Tmjr1GHNnjOIfy0NT32Vg8LqJqnLJCKiIYB9pMhsKZUKzBrpjZmRXthdcB6paQXIOn0eXx04h68PnkNSlDf+mBCKKF8nqUslIupzvFbsxvTV749BisyeQqHAlDB3TAlzx8GzF/DvtELsOFGJTUcrsOloBW4e7oElCcMQG+zK5p5EZPYsLS0BAC0tLbCxsZG4GvPV0iJ2g7/4+zQV2x/0I7Y/kE5eRSNWpRdgY04ZLvbyjAl0wZLEYUgM92SgIiKzVl5ejrq6Onh6esLW1pb/pvWCIAhoaWlBVVUVnJ2d4ePj02NMb76/GaT6EYOU9M6eb8EHmYX4av85dHQ384zwccQjCcMwZ5QPVEr+40NE5kcQBFRUVKCurk7qUsyWs7MzvL29LxtCGaRkgkFKPqoa2vCfn4vw+S/FaO4Q78sU5GaLh+OHYf44X1hZsLknEZkfrVYryW1RzJ2lpSVUqiv/u88gJRMMUvJT19KBT/YU4+M9RahrEf/x8XK0woNTQ7AoNgB2Vlw2SEQ01DFIyQSDlHw1t3fhv9ln8b8/nUZlg9jM09nWEvdNCkbKpEA426olrpCIiKTCICUTDFLy196lxfqDpViVUYji8+IVHHZqFe6+KRAPTAmGpyPvY0VENNQwSMkEg5T56NLqsCm3Av9OK8DJikYAgNpCid/E+OEPNw9DgJutxBUSEdFAYZCSCQYp8yMIAtLyqpCaVogDxRcAACqlAsmjffBIQijCvR0krpCIiPobg5RMMEiZL0EQkF1Ui9T0QmTmV+u3z4jwwh8Th2FcgIuE1RERUX9ikJIJBqnB4ei5eqzKKMDm3Apc/GuZGOKGJYmhmBzqxkZ4RESDDIOUTDBIDS4FVU34IKMQ6w+Voqu7XXq0nxMeSQjFzEgvKNnck4hoUGCQkgkGqcGptK4V/5t5Gl/sO4u2TrFbepinPR5JGIbkaA0sVUqJKyQiohvBICUTDFKDW01TOz7eXYRP9xSjsb0LAODrbIOH40Pwm/H+sLZkt3QiInPEICUTDFJDQ0NbJz77pRirfyrC+eYOAIC7vRV+PyUY/3NTABysb+zO4kRENLAYpGSCQWpoae3Q4sv9Jfgw8zRK61oBAA7WFkiZGIT7JgfBzd5K4gqJiOh6MEjJBIPU0NSp1eG7w2VYlV6AwupmAIC1pRKLYgPw4NQQaJxtJK6QiIiuhkFKJhikhjadTsC24xVITSvE0dJ6AIClSoH5Y33xcPwwhHjYS1whERFdDoOUTDBIESA29/y5oAapaQX45XQtAEChAJKivDE7ygdxwa7w4j39iIhkg0FKJhik6FIHii9gVXoBdpyoMtoe5GaL2GBXxAa7IS7YFX4uNmz0SUQkEQYpmWCQois5WdGAL/edQ/aZ8zhe1gDdJX+FGidrfbCKDXbFMA87BisiogHCICUTDFJ0PRraOnHgzAXsLapFdtF5HDlXr++cfpGbnRqxwa6I6w5XI7wd2EmdiKifMEjJBIMUmaKlowuHztbpg9Whs3Vo79IZjXG0tsCEIFfEhYjBaqTGkR3ViYj6CIOUTDBIUV9o79Li6Ll67C2qxd6iWhw4U4vmDq3RGFu1CjGBLvoZq9F+TuysTkRkIgYpmWCQov7QpdXheHkD9p4Wg9W+M7Wob+00GqO2UGKMvzPigl0RF+yGcYHOsFVbSFQxEZF5YZCSCQYpGgg6nYD8qkbsPV2L7O5Zq5qmdqMxFkoFonydxGAV4oqYQFc42fDWNUREl8MgJRMMUiQFQRBQVNOsD1V7T59HWX2b0RiFAojwdvzVAnZX3sKGiKgbg5RMMEiRXJy70ILsIsOMVVFNc48xoZ72RsHKx4m3siGioYlBSiYYpEiuqhrakH2mO1idrkVeZWOPMQGuF5uEiuEqwNWWvayIaEhgkJIJBikyFxeaO7DvjGHG6lhZfY8mod6O1kbBKtTTnsGKiAYlBimZYJAic9XY1okDxRf0pwNzztWhU2v8T4WrnRqxQa76cBXh4wgVm4QS0SDAICUTDFI0WLR2aHGoxBCsDp69gLZO4yahDt1NQi8Gq1G+TmwSSkRmiUFKJhikaLDq6NLhaOnF7uu12H/mAprau4zG2FiqMC7QGXHd9wsc4+/MJqFEZBYYpGSCQYqGii6tDifKG7G36Lw4a3WmFnUtlzQJVSkR7e+kD1bjAl1gb8UmoUQkPwxSMsEgRUOVTifgVFUTsovO629tU91o3CRUpVQgSuOIuBA3xAa5YkKQK5xs2SSUiKTHICUTDFJEIkEQUHy+BXu7g1V2US3OXWg1GqNQAOFeDt3d190wIcgVHg5sEkpEA49BSiYYpIiurLSuFdndpwL3FtXidHXPJqEhHnb6BqFxwW7QOLNJKBH1PwYpmWCQIrp+1Y3t2HdGvKXN3iKxSeil/zr5udjo+1jFBbsh0I1NQomo7zFIyQSDFJHp6lo6sP/MBWR3h6vcsgZoL+kS6ulgZQhWIW4I9bCHkr2siOgGMUjJBIMUUd9pau/Cwe4moXuLziOnpB4dWuNeVi62lvpeVnHBbojUsEkoEfUeg5RMMEgR9Z+2Ti0Ol9Tpg9WB4p5NQu2tLDA+yEU/azXK1xlqCzYJJaKrY5CSCQYpooHT0aVDblm9vvv6vqJaNF7SJNTaUolxAS767utj/V1go2aTUCIyxiAlEwxSRNLR6gScKG/QB6vsM7Wobe4wGmOpUiDaz1kfrGICXeBgzV5WREMdg5RMMEgRyYcgCCioatL3sdpbdB6VDcZNQpUKIMrXSX8z5glBrnCxU0tUMRFJhUFKJhikiORLEAScrW3RB6vsolqcrW3pMS7cywFxId03Yw5yhaejtQTVEtFAYpCSCQYpIvNSVtcq9rLqDlYFVU09xgS72yE2yBVxIWLLBV82CSUadBikZIJBisi81TS1Y1+RIVidqGjo0SQ0zNMeCeEeSAz3xPggV14VSDQIMEjJBIMU0eBS39qJ/WfEUPVLUS2OnqvDr3uE2qlVmBzqjoRwTySEe/CWNkRmikFKJhikiAa3+pZO/FRQjbST1cjIr0ZNk/Hi9XAvBySM8EDCcE+MD3KBpYqzVUTmgEFKJhikiIYOnU7AsbIGpOdVIS2vCodK6oxOAzpYWWByqDsSR3ggIdwTXly0TiRbDFIywSBFNHRdaO5A5qlqZORVIz2/ukcPqwgfRySGi6FqXIAzLDhbRSQbDFIywSBFRIA4W3W0tB5peVVIy6vGkXPGs1WO1haYGuaBhHAPxId7wNOBs1VEUmKQkgkGKSK6nPNN7cg8VY30PHFtVV1Lp9H+KF9HJAz3ROIID4zxd+GNl4kGGIOUTDBIEdG1aHUCcs7VIf1kFdLzq3HkXL3RficbS9w83AMJw8XZKnd7K4kqJRo6GKRkgkGKiHqrurEdGfnVSM+rQmZ+NRraDDdeViiA0b5OiA/3RGK4B0b7OXO2iqgfMEjJBIMUEd2ILq0Oh0vqkJZXhfS8ahwrazDa72Jrifjh4oL1m4d7wJX3BSTqEwxSMsEgRUR9qaqhDends1U/napB4yWzVdF+zkgMF9dWRWmcoORsFZFJGKRkgkGKiPpLp1aHg8UXkJ5fjbSTVThZ0Wi0391eLa6tCvfEzWHucLblbBXR9WKQkgkGKSIaKOX1rcjIq0ZaXhV2F5xHU7thtkqpAMYGuOj7VkX6OHK2iugqGKRkgkGKiKTQ0aXD/uJafbDKr2wy2u/hYIX44eKNlqeEucPJxlKiSonkiUFKJhikiEgOSutakd69YH13QQ1aOrT6fSqlAjEBLogPF4NVhI8DFArOVtHQxiAlEwxSRCQ37V1a7D9zAWndfasKqoxnq7wcrZAw3BMJ4R6YHOYOR2vOVtHQwyAlEwxSRCR3JbUt4pWAJ6uwu7AGbZ06/T4LpQIxgS5IHOGJxHBPDPey52wVDQkMUjLBIEVE5qStU4vsolqk5VUhI68ap2uajfb7OFkjIbx7tirUHfZWFhJVStS/GKRkgkGKiMxZ8flmpHcvWM8qPI/2LsNslaVKgQlBrkjsDlahnpytosGDQUomGKSIaLBo69Qi6/R5/ZWAxedbjPb7OtsgoXvB+qRQN9iqOVtF5otBSiYYpIhosCqqadYvWP/l9Hl0/Gq2Sq1SIi7EVX8aMMTdjrNVZFYYpGSCQYqIhoKWji5kFZ7XnwY8d6HVaH+Aq61+tuqmEDfYqFUSVUp0fRikZIJBioiGGkEQUFjdrO9btbfoPDq1hq8ZKwslbgpx0werIHc7CaslujwGKZlgkCKioa65vQt7Cs/rrwQsrTOerQpys0VCuCcSR3giLtgV1pacrSLpMUj1kx9++AF//vOfodPp8Je//AUPPPDAVcczSBERGQiCgFNVTUjPq0LayWrsO1OLLp3hK8jaUolJw9yREO6BhOGeCHCzlbBaGsoYpPpBV1cXIiMjkZaWBicnJ8TExGDPnj1wc3O74nMYpIiIrqyxrRO7C87rTwNWNLQZ7Q/xsNO3V4gNdoWVBWeraGD05vub16dep+zsbIwcORK+vr4AgKSkJGzbtg2LFi2SuDIiIvPkYG2J2VHemB3lDUEQcLKiUb9g/UDxBZyubsbp6iKs/rkItmoVJg1z018J6OfC2SqSB6XUBTQ2NmLp0qUIDAyEjY0NJk2ahH379vXpe2RmZiI5ORkajQYKhQIbNmy47LjU1FQEBQXB2toacXFxyM7O1u8rKyvThygA8PX1RWlpaZ/WSUQ0VCkUCkT4OOKRhGH48g8TcfAft+Dfd4/DneP94OFghZYOLXacqMLfN+RiyqtpuOWtDLy06QT2FNQYtV4gGmiSz0g98MADyM3Nxdq1a6HRaPDZZ59hxowZOH78uFFwuWj37t2IjY2FpaXxjTSPHz8ONzc3eHl59XhOc3MzoqOjcf/992PBggWXrWPdunVYtmwZ3n//fcTFxWHFihWYNWsW8vLy4Onp2TcHS0RE18XJxhK3jvLBraN8IAgCjpU1ICO/Gunds1WnqppwqqoJH2aehp1ahcmh7kgcIc5W+TjZSF0+DSGSrpFqbW2Fg4MDvvvuO8yZM0e/PSYmBklJSfjXv/5lNF6n02HcuHEICwvDF198AZVKPF+el5eH+Ph4LFu2DE8//fRV31OhUGD9+vWYN2+e0fa4uDhMmDABK1eu1L+Xv78/HnvsMSxfvhx79uzB66+/jvXr1wMAli5ditjYWCxevLjHe6SmpiI1NRVarRb5+flcI0VE1IfqWzrxU0E10k5WIyO/CjVNHUb7R3g7IL67vUJMoAssVZKffCEzYzaLzRsbG+Ho6IgdO3Zg+vTp+u1TpkyBhYUF0tPTezynrKwMN998M+Li4rB27VoUFRXh5ptvRnJyMt5///1rvuflglRHRwdsbW3x9ddfG21PSUlBXV0dvvvuO3R1dSEiIgLp6elcbE5EJBM6nThblZZXhfS8KhwqqcOvv9UcrCwwJaz7SsBwT3g5WktXLJkNs1ls7uDggIkTJ+KFF15AREQEvLy88N///hdZWVkIDQ297HM0Gg127dqFqVOnYvHixcjKysKMGTOwatUqk+uoqamBVqvtcVrQy8sLJ0+eBABYWFjgzTffRGJiInQ6HZ5++umrhigiIup/SqUCo/ycMMrPCX+aHoYLzR3IPFWN9LxqZORXo7a5A5tzK7A5twIAEOHjiMRwDySO8MRYf2dYcLaKbpDka6TWrl2L+++/H76+vlCpVBg3bhwWLVqEAwcOXPE5AQEBWLt2LeLj4xESEoLVq1cPyH2c5s6di7lz5/b7+xARkWlc7NS4fYwvbh/jC61OwNHSerFvVV41jpyrw4nyBpwob8C/0wvhaG2BxBGeSB6twc3DPaC2YKii3pM8SA0bNgwZGRlobm5GQ0MDfHx8cNdddyEkJOSKz6msrMRDDz2E5ORk7Nu3D0888QTee+89k2twd3eHSqVCZWVlj/fx9vY2+XWJiEg6KqUCY/ydMcbfGUtnDMf5pnZknhLXVmWeqkZdSye+O1yG7w6XwdHaAklRPpg7RoObQtygUvImy3R9JA9SF9nZ2cHOzg4XLlzA1q1b8dprr112XE1NDaZPn46IiAh89dVXyM/PR0JCAqysrPDGG2+Y9N5qtRoxMTHYuXOnfo2UTqfDzp078eijj5p6SEREJCNu9laYP9YP88f6QasTcLjkAn44Uo4fj5SjqrEd6/aXYN3+ErjbW+G20T5IjtZgXIDzgJzxIPMleWfzrVu3QhAEhIeHo6CgAE899RSsra3x008/9WhxoNPpEBcXB09PT6xfvx5qtRoAkJOTg2nTpuHvf/87nnjiiR7v0dTUhIKCAgDA2LFj8dZbbyExMRGurq4ICAgAILY/SElJwQcffIDY2FisWLECX375JU6ePHnZlgrXg4vNiYjkT6sTsLfoPL7PKcOmoxWob+3U7/N1tkFytAZzozWI8HFgqBoizOaqPQD48ssv8de//hXnzp2Dq6srFi5ciBdffBFOTk6XHb99+3ZMnToV1tbGV14cOnQIHh4e8PPz6/Gc9PR0JCYm9tiekpKCNWvW6H9euXIlXn/9dVRUVGDMmDF49913ERcXZ/KxMUgREZmXji4dfi6oxsbDZdh2vBItHVr9vlBPeySP1mDuGA2C3e0krJL6m1kFqcGMQYqIyHy1dmix62QVNuaUIi2v2qiDepSvI+ZGa3DbaA00zmwAOtgwSMkEgxQR0eDQ0NaJbccqsTGnDLsLaqDVGb46Y4NckRwtdmF3s7eSsErqKwxSMsEgRUQ0+Jxvasem3Ap8f7gM2Wdq9dtVSgUmh7ojebQPZkV5w9Ha8iqvQnLGICUTDFJERINbWV0rfjxSjo05ZThaWq/frrZQIjHcA8nRGkwf4QUbtUrCKqm3GKRkgkGKiGjoOF3dhB+6Q1VBVZN+u51ahVsivZAcrcHUMDb+NAcMUjLBIEVENPQIgoAT5Y34/kgZvs8pw7kLrfp9zraWSIryRvJoDeLY+FO2GKRkgkGKiGhoEwQBB8/W4fucMvxwpBw1Te36fZ4OVpjT3fhzrD8bf8oJg5RMMEgREdFFWp2AX06LjT835xo3/vR3tUHyaA2SozUY4c3Gn1JjkJIJBikiIrqcji4dfjpVjY05Zdh+SePPME97zI0WQ1UQG39KgkFKJhikiIjoWlo6usTGn4fLkJ5XjQ6tofHnaD8nfeNPbyfrq7wK9SUGKZlgkCIiot6ob+3EtmMV2JhThj2F5/WNPxUKYEKQK+ZGa3DrKB+42qklrnRwY5CSCQYpIiIyVU1TOzYdLcf3OWXYd+aCfrtKqcCUUHfMjdZg5kgvOLDxZ59jkJIJBikiIuoLpXWt+CGnDN8fKUNuaYN+u9pCiWnhnpg7RoNpIzxhbcnGn32BQUomGKSIiKivFVY34fucMmzMKcPp6mb9dju1CjNHemNutAZTwtxhqWLjT1MxSMkEgxQREfUXQRBwvLwBG3PK8ENOOUrrLm386YO50RrEBruy8WcvMUjJBIMUERENBJ1OwKGSC9h4uAw/Hi1HTVOHfp+XoxXmjNJg7hgNov2c2KPqOjBIyQSDFBERDbQurQ6/nK7FxpxSbM6tQGNbl35foJutvvFnuLeDhFXKG4OUTDBIERGRlNq7tMjMr8HGnDLsOF6J1k5D489wLwfMHaNB8mgNAtxsJaxSfhikZIJBioiI5KKlows7ToiNPzPyq9CpNXz9R/s7dzf+9IGXIxt/MkjJBIMUERHJUX1LJ7bqG3/WoLvvJxQKIC7YFXOjfZEU5Q2XIdr4k0FKJhikiIhI7qoa27D5qBiqDhQbGn9aKBWYGuaOuWM0uCXSG/ZWFhJWObAYpGSCQYqIiMzJuQst+OFIOTYeLsPxckPjTysLJaZHeGJutAYJ4YO/8SeDlEwwSBERkbkqqBIbf36fU4bTNYbGn/ZWFpg50gtzozWYHDo4G38ySMkEgxQREZk7QRBwrKxBH6rK6tv0+1zt1EiKErupTwhyhXKQNP5kkJIJBikiIhpMdDoBB85ewPc5ZfjxSDnONxsaf3o7WuO20T6YO0aDUb7m3fiTQUomGKSIiGiw6tLqsKfwPL7PKcOWY8aNP4PcbJEcrcHcaA3CvMyv8SeDlEwwSBER0VDQ1qlFRn41NuaUYeeJSrR16vT7Rng76EOVv6t5NP5kkJIJBikiIhpqmtu7sONEJb7PKUNGfrVR488xv2r86Snjxp8MUjLBIEVERENZXUsHtuRW4PsjZcgqPG/U+POmYDfMHaNBUpQ3nG3l1fiTQUomGKSIiIhEVY1t+PFIOb7PKcPBs3X67RZKBW4e7oG50RrcEukFOxk0/mSQkgkGKSIiop5Kalvw/ZEyfJ9TjhO/avxpbanE9BFeSI7WICHcQ7LGnwxSMsEgRUREdHWnKhvxfU4ZNuaU4cz5Fv12BysLzIryRnK0BpOHucFiABt/MkjJBIMUERHR9REEAbmlDdiYU4ofjpSj/FeNP93s1Lh1lA+SozUYH+jS740/GaRkgkGKiIio93Q6AfuLL2BjTik2Ha1A7a8af2qcrHFbtAbJozWI8nXsl8afDFIywSBFRER0Yzq7G39uPFyGbccq0NhuaPwZ7G6HBWN98dj0sD59z958f0u/NJ6IiIjoCixVSsQP90D8cA+0dUYhPa8a3+eUYceJShTVNONQSZ2k9TFIERERkVmwtlRhdpQ3Zkd5o6m9CzuOV8JL4saeDFJERERkduytLDBvrK/UZWDgriUkIiIiGmQYpIiIiIhMZFKQKikpwblz5/Q/Z2dnY+nSpfjwww/7rDAiIiIiuTMpSC1evBhpaWkAgIqKCtxyyy3Izs7G3/72Nzz//PN9WiARERGRXJkUpHJzcxEbGwsA+PLLLxEVFYU9e/bg888/x5o1a/qyPiIiIiLZMilIdXZ2wsrKCgCwY8cOzJ07FwAwYsQIlJeX9111RERERDJmUpAaOXIk3n//ffz000/Yvn07Zs+eDQAoKyuDm5tbnxZIREREJFcmBalXX30VH3zwARISErBo0SJER0cDADZu3Kg/5UdEREQ02Jl8rz2tVouGhga4uLjot505cwa2trbw9PTsswLNGe+1R0REZH568/1t0oxUa2sr2tvb9SGquLgYK1asQF5eHkMUERERDRkmBanbb78dn376KQCgrq4OcXFxePPNNzFv3jysWrWqTwskIiIikiuTgtTBgwcxdepUAMDXX38NLy8vFBcX49NPP8W7777bpwUSERERyZVJQaqlpQUODg4AgG3btmHBggVQKpW46aabUFxc3KcFEhEREcmVSUEqNDQUGzZsQElJCbZu3YqZM2cCAKqqqriomoiIiIYMk4LUM888gyeffBJBQUGIjY3FxIkTAYizU2PHju3TAomIiIjkyuT2BxUVFSgvL0d0dDSUSjGPZWdnw9HRESNGjOjTIs0V2x8QERGZn958f1uY+ibe3t7w9vbGuXPnAAB+fn5sxklERERDikmn9nQ6HZ5//nk4OTkhMDAQgYGBcHZ2xgsvvACdTtfXNRIRERHJkkkzUn/729+wevVqvPLKK5g8eTIA4Oeff8Zzzz2HtrY2vPjii31aJBEREZEcmbRGSqPR4P3338fcuXONtn/33Xf44x//iNLS0j4r0JxxjRQREZH56fdbxNTW1l52QfmIESNQW1tryksSERERmR2TglR0dDRWrlzZY/vKlSsxevToGy6KiIiIyByYtEbqtddew5w5c7Bjxw59D6msrCyUlJRg06ZNfVogERERkVyZNCMVHx+P/Px8zJ8/H3V1dairq8OCBQtw7NgxrF27tq9rJCIiIpIlkxtyXk5OTg7GjRsHrVbbVy9p1rjYnIiIyPz0+2JzIiIiImKQIiIiIjIZgxQRERGRiXp11d6CBQuuur+uru5GaiEiIiIyK70KUk5OTtfc/7vf/e6GCiIiIiIyF70KUh9//HF/1UFERERkdrhGioiIiMhEDFJEREREJmKQIiIiIjIRgxQRERGRiRikiIiIiEzEIEVERERkIgYpIiIiIhMxSBERERGZiEGKiIiIyEQMUkREREQmYpAiIiIiMhGDFBEREZGJGKSIiIiITMQgRURERGQiBikiIiIiEzFIEREREZmIQYqIiIjIRAxSRERERCZikCIiIiIyEYMUERERkYkspC6ATFBfCnz+GyD4ZiAkHgicDFg7Sl0VERHRkMMZqV744YcfEB4ejrCwMPznP/+RrpCiDKDqGLB3FfDf3wKvBgH/Ox3Y+TxwOgPobJOuNiIioiFEIQiCIHUR5qCrqwuRkZFIS0uDk5MTYmJisGfPHri5uV3xOQ0NDXByckJ9fT0cHftwxqilFjidDhRliqGq9rTxfpUVEBAHBMeLD81YQMXJRyIiouvRm+9vfrtep+zsbIwcORK+vr4AgKSkJGzbtg2LFi0a+GJsXYGoBeIDAOpKDKHqdAbQVNH9cyaAFwArR/H038VTgZ6RgEIx8HUTERENMpKf2tNqtfjHP/6B4OBg2NjYYNiwYXjhhRfQlxNlmZmZSE5OhkajgUKhwIYNGy47LjU1FUFBQbC2tkZcXByys7P1+8rKyvQhCgB8fX1RWlraZzXeEGd/YOzdwIIPgT+fBJbsA259AxhxG2DtBLQ3APmbga1/BVZNAl4PBb66DziwRpzN4qQkERGRSSSfkXr11VexatUqfPLJJxg5ciT279+P++67D05OTvjTn/7UY/zu3bsRGxsLS0tLo+3Hjx+Hm5sbvLy8ejynubkZ0dHRuP/++7FgwYLL1rFu3TosW7YM77//PuLi4rBixQrMmjULeXl58PT07JuDHQgKBeAxXHzEPgjotEDFEXF26nQGcDYLaKkBjn0rPgDAKQAIubn7VODNgIO3tMdARERkJiRfI3XbbbfBy8sLq1ev1m9buHAhbGxs8NlnnxmN1el0GDduHMLCwvDFF19ApVIBAPLy8hAfH49ly5bh6aefvur7KRQKrF+/HvPmzTPaHhcXhwkTJmDlypX69/L398djjz2G5cuXY8+ePXj99dexfv16AMDSpUsRGxuLxYsXX/G9+m2N1I3o6gBK94uhqigDOLcP0HUZj/EYIQaq4HggaApg4yxJqURERFLozfe35Kf2Jk2ahJ07dyI/Px8AkJOTg59//hlJSUk9xiqVSmzatAmHDh3C7373O+h0OhQWFmLatGmYN2/eNUPUlXR0dODAgQOYMWOG0XvNmDEDWVlZAIDY2Fjk5uaitLQUTU1N2Lx5M2bNmnXZ10tNTUVkZCQmTJhgUj39ykINBE4CEv8K3L8F+EsxcPc3wKTHAJ9oAAqg+iSQ/SGw7m7gtWDgwwRg+7NA4S6go0XqIyAiIpINyU/tLV++HA0NDRgxYgRUKhW0Wi1efPFF3H333Zcdr9FosGvXLkydOhWLFy9GVlYWZsyYgVWrVplcQ01NDbRabY/Tgl5eXjh58iQAwMLCAm+++SYSExOh0+nw9NNPX/GKvSVLlmDJkiX6RCtrVvZA2AzxAYhXBJ75yXAq8PwpoOyQ+Ni9AlCpAb9Yw8J13xhAZXnVtyAiIhqsJA9SX375JT7//HP83//9H0aOHInDhw9j6dKl0Gg0SElJuexzAgICsHbtWsTHxyMkJASrV6+GYgCuQps7dy7mzp3b7+8jKVtXIPJ28QEADWWGUFWUATSUAsU/i4/0lwBLO3GGK6S71YJXFKCUfKKTiIhoQEgepJ566iksX74cv/3tbwEAo0aNQnFxMV5++eUrBqnKyko89NBDSE5Oxr59+/DEE0/gvffeM7kGd3d3qFQqVFZW9ngfb+8hvvDaUQNE/1Z8CIJ4lZ++h1Um0FoLFGwXHwBg4woETzX0sHIbxlYLREQ0aEkepFpaWqC8ZAZDpVJBp9NddnxNTQ2mT5+OiIgIfPXVV8jPz0dCQgKsrKzwxhtvmFSDWq1GTEwMdu7cqV+ErtPpsHPnTjz66KMmveagpFCIwchtGDDh94BOB1TmGnpYFe8Rg9Xx78QHADj6Gq4GDIkXgxkREdEgIXmQSk5OxosvvoiAgACMHDkShw4dwltvvYX777+/x1idToekpCQEBgZi3bp1sLCwQGRkJLZv345p06bB19cXTzzxRI/nNTU1oaCgQP9zUVERDh8+DFdXVwQEBAAAli1bhpSUFIwfPx6xsbFYsWIFmpubcd999/XfwZs7pRLwGS0+Jj0KaDuB0oOGxqDnssVTgTn/Jz4AwC3MEKqCpoqnEomIiMyU5O0PGhsb8Y9//APr169HVVUVNBoNFi1ahGeeeQZqtbrH+O3bt2Pq1KmwtrY22n7o0CF4eHjAz8+vx3PS09ORmJjYY3tKSgrWrFmj/3nlypV4/fXXUVFRgTFjxuDdd99FXFycyccmy/YHA6mjBSj5pXt9VSZQfhgQfj3TqAC8RxnWVwVMFBe/ExERSag339+SB6nBbMgHqUu11gFnfjacCqw+abxfaQH4TTD0sPKbILZrICIiGkAMUjLBIHUNjZXdoSodOJ0J1J813m9pCwTcZFhj5RMNKFWSlEpEREMHg5RMMEj1Um2ROFN18YrA5mrj/dbOYqf14HjxdKD7cF4RSEREfY5BSiYYpG6AIABVxw09rIp3izdf/jV7b8PC9eB48ebNREREN4hBSiYYpPqQtktcrH6xh9XZXwBtu/EYl2BDqAq+GbBzl6JSIiIycwxSMsEg1Y8624CSvYaF66UHAUFrPMYryrBwPXASYM3PgIiIro1BSiYYpAZQW4PYEPRiD6uqY8b7FSrxvoAXTwX6xQKW1pd/LSIiGtIYpGSCQUpCTdXAmUxDD6sLRcb7LawB/zjDqUCfMYBK8v60REQkAwxSMsEgJSN1Z41vvtxkfF9FWDl2XxHYfSrQM4JXBBIRDVEMUjLBICVTggBU5xnWV535CWirNx5j52EIVSHxgEuQJKUSEdHAY5CSCQYpM6HTAuU5hvVVZ38BulqNxzgHdF8N2H1FoIOXNLUSEVG/Y5CSCQYpM9XVDpzbZzgVWLof0HUZj/GIMCxcD5wM2DhLUioREfU9BimZYJAaJNobxVmq0+nirFXFUeP9CqW4WP3iwnX/OEBtK0WlRETUBxikZIJBapBqPi+uq7p4O5vzBcb7VWoxTF1cY+U7DlBZSlMrERH1GoOUTDBIDRH15wz3BzydATSWGe9X24sNQS8uXPccCSiV0tRKRETXxCAlEwxSQ5AgAOcLgaJ0MVSd+QlovWA8xtYNCJpqWF/Fmy8TEckKg5RMMEgRdDqg8qihMWjxHqCz2XiMjSsQMBEIuEmcufKJ5qlAIiIJMUjJBIMU9dDVAZQeEEPVmZ/EqwO72ozHWNgAfuPFUBVwk3g7Gyt7aeolIhqCGKRkgkGKrqmrQ+xhdXaPeGXg2ayepwIVKsB7lCFYBUwE7D2lqZeIaAhgkJIJBinqNZ0OqMkTA1Vxlhiu6s/2HOc6DAicCAR0hyvXEK6zIiLqIwxSMsEgRX2i/pwYqIq7Z62qjgO45M/W3qt7tqo7WHmPApQqScolIjJ3DFIywSBF/aL1AlCS3R2ssoDSg4Cu03iM2gHwjxVPAwZOBHxjAEsbaeolIjIzDFIywSBFA6KzVQxTZ7PER0k20N5gPEZpCWjGGq4M9I8DbF2lqZeISOYYpGSCQYokodMClccMwao4C2iq6DnOI6J7nVX3w9l/4GslIpIhBimZYJAiWRAE4MIZ42B1/lTPcY5+3cGqe62Vxwh2YCeiIYlBSiYYpEi2mmt+dWVgltiCQdAaj7F2NrRbCJgonhq0UEtSLhHRQGKQkgkGKTIb7U1A6X5DsDq3D+hsMR5jYS0uWr8YrPxjAWv+75qIBh8GKZlgkCKzpe0EKo4YgtXZLKDlvPEYhRLwijJcGRgwEXDwlqZeIqI+xCAlEwxSNGgIAlBzyhCqzmaJ664u5RL8q2A1CXAbxkahRGR2GKRkgkGKBrWGMsNtbYqzgMpc9GgUaudhvM7KezSgspCkXCKi68UgJRMMUjSktNWLPawuBqvSA4C23XiMpR3gP8EQrPzGA2o7aeolIroCBimZYJCiIa2rHSg7ZAhWJb+IYevXlBaAT7QhWAVMBOzcpKmXiKgbg5RMMEgR/YpOB1SfMNwz8GwW0FDac5z7cEOoCpwIOAdynRURDSgGKZlgkCK6CkEA6kuMrwysPtlznIPGcGubgJsAz0jekJmI+hWDlEwwSBH1UvN5oGQvcLZ71qrsEKDrMh5j5ST2sLp4ZaBmLGBpLU29RDQoMUjJBIMU0Q3qaBEXrf/6hswdTcZjVOruRqHdt7bxjwVsnCUpl4gGBwYpmWCQIupj2i6xzcLZLMNaq+aqSwYpAK+Rxm0XnHwlKZeIzBODlEwwSBH1M0EAak8b3zewtrDnOOcAcbbq4lor9+FcwE5EV8QgJRMMUkQSaKzsPhX4i7jWquIoIOiMx9i4ds9WdQcrn2hAZSlNvUQkOwxSMsEgRSQD7Y3djUK7Wy6c2w90tRqPsbARm4NevDLQLxawspemXiKSHIOUTDBIEclQVwdQnmN838DWC8ZjFCrAe1R3sOqeubL3lKZeIhpwDFIywSBFZAZ0OqAm39ByoTgLqD/bc5xbqOHKwICbANcQrrMiGqQYpGSCQYrITNWf6w5V3eGq6jh63JDZ3gsInAyMnAeEzQQsbaSolIj6AYOUTDBIEQ0SrRfEdVYXg1XZQUDbYdivdgBGzAGiFgIhCYCFWrJSiejGMUjJBIMU0SDV2SY2Cs3fAuR+CzScM+yzcQEi5oqhKmgKb2dDZIYYpGSCQYpoCNDpgHP7gNxvgGPrjRuE2nsBI+eLocpvAtdUEZkJBimZYJAiGmK0XUDxz2KoOr4RaKsz7HMKAKLmA1F3iFcEMlQRyRaDlEwwSBENYV0dwOk0MVSd/NH4HoFuYeIsVdRCwGO4dDUS0WUxSMkEgxQRAQA6W4H8rWKoyt8KaNsN+7xGAVELxIdLkGQlEpEBg5RMMEgRUQ9tDUDeZjFUFe4EdF2GfX4TxFmqyHmAo49kJRINdQxSMsEgRURX1VILnNgohqqin2DoVaUQr/iLWgBE3A7YuUlZJdGQwyAlEwxSRHTdGiuA49+Joapkr2G70gIISRRnqkbcClg7SVcj0RDBICUTDFJEZJILxWIrhdxvgIojhu0qKyDsFjFUDZ8NqG2lq5FoEGOQkgkGKSK6YTWnxKafuV+L9wS8yNJOnKGKWggMmwZYWElXI9EgwyAlEwxSRNRnBAGozBVnqXK/Aep+dWNlaycgIlnsURU0FVBZSFcn0SDAICUTDFJE1C8EQbxFTe434mxVU4Vhn52HeNVf1ELAPw5QKiUrk8hcMUjJBIMUEfU7nVa8mXLuN+Ji9dZawz5HX8MtajRj2U2d6DoxSMkEgxQRDShtJ3A6Q1xPdeIHoKPRsM81xNBN3TNCuhqJzACDlEwwSBGRZDrbgILt4kxV3hagq9WwzzOyu5v6QjFgEZERBimZYJAiIllobwLyt4ih6tR2QNdp2KcZJwaqkfMBJ1/paiSSEQYpmWCQIiLZab0gnvbL/QYoygAEnWFfwCRxpipyHmDvIVmJRFJjkJIJBikikrWmKkM39bNZhu0KFRAS391N/TbAxlmyEomkwCAlEwxSRGQ26s8ZuqmXHTJsV6mB0BliqApPAtR20tVINEAYpGSCQYqIzNL5QuDYt8DRb4DqE4btlrbirWmiForhytJauhqJ+hGDlEwwSBGR2as8buimfqHIsN3KUTztF7VQPA2ospSuRqI+xiAlEwxSRDRoCIJ4yu9iN/XGMsM+Wzcg8nYxVAVMYjd1MnsMUjLBIEVEg5JOB5T8IoaqYxuAlhrDPgef7m7qdwC+49hNncwSg5RMMEgR0aCn7QLOZHbfouZ7oL3esM850NBN3WskQxWZDQYpmWCQIqIhpasdKNjZ3U19E9DZYtjnHm4IVe6h0tVIdB0YpGSCQYqIhqyOZiB/a3c39W2AtsOwzye6u5v6AsDZX7oaia6AQUomGKSIiAC01QMnfxRDVWEaIGgN+/zjxPVUkbcDDl7S1Uj0KwxSMsEgRUR0ieYa4MRGsUdV8W4A3V9BCiUQNFWcqYpIBmxdJS2ThjYGKZlgkCIiuoqGMvGqv9xvgNL9hu1KC2DY9O5b1NwKWDlIViINTQxSMsEgRUR0nWqLxG7qud8ClbmG7RbWwPBZYqgKmwlY2khXIw0ZDFIywSBFRGSCqpPdt6j5GqgtNGxX2wMj5ohrqkISAAu1ZCXS4MYgJRMMUkREN0AQgIojYqA6th6oLzHss3EBIuaKM1VBUwClSro6adBhkJIJBikioj6i0wHn9nV3U18PNFcZ9tl7AZHzgFF3AH4T2PiTbhiDlEwwSBER9QOdFjjzM5D7NXB8I9BWZ9jnFABEzRdnqrxHM1SRSRikZIJBioion3V1AKfTxJmqkz8CHU2GfW5hhm7qHsOlq5HMDoOUTDBIERENoM5W427qXW2GfV6jgKgF4sMlSLISyTwwSMkEgxQRkUTaGoC8zd3d1HcCui7DPt/x3beomQ84+khXI8kWg5RMMEgREclAS63YTT33G6DoJ+i7qUMBBNwEDJ8NhCcB7sO5pooAMEjJBoMUEZHMNFYAx78TQ1XJXuN9LsFioBo+CwiYxD5VQxiDlEwwSBERyVjdWSBvC5C/BTjzE6DtMOyzcgRCp4uzVWEzee+/IYZBSiYYpIiIzER7I1CYJi5WP7UVaK427FMoAf84caZqeBLgEc5TgIMcg5RMMEgREZkhnQ4oPSDOVOVvMb73HyBe9Td8tvgInMxTgIMQg5RMMEgREQ0CdWfFmar8LUBRpvEpQLUDEDpNnKkKuwWwc5euTuozDFIywSBFRDTItDcBp9OB/M1A/jbjW9VAAfjHGq4C9BjBU4BmikFKJhikiIgGMZ0OKDskhqq8LUDlUeP9zoHdoeriKUAraeqkXmOQkgkGKSKiIaT+nHj6L+/iKcB2wz61PTBsmjhTFTaTpwBljkFKJhikiIiGqI5m8RRg3mbxdjVNlb/aqQD8JogzVcNnA56RPAUoMwxSMsEgRURE0OmA8kPigvW8zUDFEeP9TgFia4Xw2UDQVJ4ClAEGKZlgkCIioh7qS8VeVXlbgKIM45srW9oBwxK7TwHOAuw9pKtzCGOQkgkGKSIiuqqOlu6rALeIM1ZNFb/aqQB8Y7pPASYBXiN5CnCAMEjJBIMUERFdN50OKD/c3bNqM1CeY7zfyd/QXT1oCmBpLUmZQwGDlEwwSBERkckaygyNQE+nX/4U4PDZYriy95SszMGIQUomGKSIiKhPdLSILRXyN4vhqrHceL9vjDhTNXwW4D2KpwBvEIOUTDBIERFRnxME8bTfxXsBlh0y3u/o130KcDYQfDNPAZqAQUomGKSIiKjfNZSLVwHmbwUK04CuVsM+S1sgJLE7WM0CHLylq9OMMEjJBIMUERENqM7W7lOA3R3WG8uM92vGGW5b4z2apwCvgEFKJhikiIhIMoIgNv+82Ai07KDxfgdNdyPQpO5TgDbS1ClDDFIywSBFRESy0Vgh3q4mbwtwOg3obDHss7Dpvgqwe23VED8FyCAlEwxSREQkS52twJmfxZmq/C1AQ6nxfp8x4kzV8NmAT/SQOwXIICUTDFJERCR7ggBU5oozVfmbgdIDxvsdfAyNQINvBtS20tQ5gBik+skPP/yAP//5z9DpdPjLX/6CBx544KrjGaSIiMjsNFaKpwDzt4hXAXY2G/ZZ2AAh8YZGoI4a6ersRwxS/aCrqwuRkZFIS0uDk5MTYmJisGfPHri5uV3xOQxSRERk1jrbxFOA+ZvFGauGc8b7faINjUB9xgBKpSRl9rXefH9bDFBNZi87OxsjR46Er68vACApKQnbtm3DokWLJK6MiIion1haA2EzxMetbwCVxwzd1c/tFxuDlucAGa8A9t6GxeohCUPiFCAASB4dg4KCoFAoejyWLFnSZ++RmZmJ5ORkaDQaKBQKbNiw4bLjUlNTERQUBGtra8TFxSE7O1u/r6ysTB+iAMDX1xelpaWXexkiIqLBR6EAvKOAm58CHtgBPJkP3J4KRCQDanugqQI4+AnwxSLgtWDg8zuBfauB+sH9XSl5kNq3bx/Ky8v1j+3btwMAfvOb31x2/O7du9HZ2dlj+/Hjx1FZWXnZ5zQ3NyM6OhqpqalXrGPdunVYtmwZnn32WRw8eBDR0dGYNWsWqqqqTDgqIiKiQc7eExj7P8BdnwFPnwb+51sg9iHAKUC8wfKprcCPy4C3I4H3pwK7XhQXsut0UlfepyQPUh4eHvD29tY/fvjhBwwbNgzx8fE9xup0OixZsgSLFy+GVqvVb8/Ly8O0adPwySefXPY9kpKS8K9//Qvz58+/Yh1vvfUWHnzwQdx3332IjIzE+++/D1tbW3z00UcAAI1GYzQDVVpaCo1mcC6yIyIi6hULKyB0OnDr68DSI8Aje4DpzwB+sQAUYmPQzNeA/50GvDUC+O5R4OSPQEfzNV9a7iQPUr/W0dGBzz77DPfffz8Ul+lZoVQqsWnTJhw6dAi/+93voNPpUFhYiGnTpmHevHl4+umnTX7fAwcOYMaMGUbvNWPGDGRlZQEAYmNjkZubi9LSUjQ1NWHz5s2YNWvWZV8vNTUVkZGRmDBhgkn1EBERmS2FAvAaCUz9M/DAduDJU8C8VUDE3O5TgJXAobXAF4uBV4OBz+4A9v0HqD937deWIVktNt+wYQPq6upw7733XnGMRqPBrl27MHXqVCxevBhZWVmYMWMGVq1aZfL71tTUQKvVwsvLy2i7l5cXTp48CQCwsLDAm2++icTEROh0Ojz99NNXvGJvyZIlWLJkiX7VPxER0ZBl7wGMWSw+utqB4t2GnlV1Z4GC7eLjxz8DXqPE+wAOTwI0Y83iKkBZBanVq1cjKSnpmqfMAgICsHbtWsTHxyMkJASrV6++7AxWX5s7dy7mzp3b7+9DREQ0KFlYAcOmiY+kV4Hqk4bu6iXZQOVR8ZH5OmDnCQyfKYaqkATAyl7q6i9LNkGquLgYO3bswLfffnvNsZWVlXjooYeQnJyMffv24YknnsB7771n8nu7u7tDpVL1WKxeWVkJb++hfb8hIiKifqFQAJ4R4mPqMqD5vKERaMFOoLkKOPSZ+FBZAcFTuxuBzgac/aWuXk82Qerjjz+Gp6cn5syZc9VxNTU1mD59OiIiIvDVV18hPz8fCQkJsLKywhtvvGHSe6vVasTExGDnzp2YN28eAHFh+86dO/Hoo4+a9JpERETUC3ZuwJhF4qOrQzwFmL9VPAV44QxQsEN8bHoS8IoyhCrfGElPAcoiSOl0Onz88cdISUmBhcWVS9LpdEhKSkJgYCDWrVsHCwsLREZGYvv27Zg2bRp8fX3xxBNP9HheU1MTCgoK9D8XFRXh8OHDcHV1RUBAAABg2bJlSElJwfjx4xEbG4sVK1agubkZ9913X98fMBEREV2ZhRoYlig+Zr8MVOeJM1X5W4CSveK9AStzgZ/eADTjgIfSJCtVFreI2bZtG2bNmoW8vDwMHz78qmO3b9+OqVOnwtra2mj7oUOH4OHhAT8/vx7PSU9PR2JiYo/tKSkpWLNmjf7nlStX4vXXX0dFRQXGjBmDd999F3FxcaYdFHiLGCIioj7XfF6cmcrfLJ4CHH0XMMe0M1JXwnvtyQSDFBERUT/q6gA6mgBb1z59Wd5rj4iIiAY/CzVg0bchqrfk36CBiIiISKYYpIiIiIhMxCBFREREZCIGKSIiIiITMUgRERERmYhBioiIiMhEDFJEREREJmKQIiIiIjIRgxQRERGRiRikiIiIiEzEIEVERERkIgYpIiIiIhMxSBERERGZyELqAgYzQRAAAA0NDRJXQkRERNfr4vf2xe/xq2GQ6keNjY0AAH9/f4krISIiot5qbGyEk5PTVccohOuJW2QSnU6HsrIyODg4QKFQ9OlrNzQ0wN/fHyUlJXB0dOzT15YDHp/5G+zHONiPDxj8x8jjM3/9dYyCIKCxsREajQZK5dVXQXFGqh8plUr4+fn163s4OjoO2j8QgMc3GAz2YxzsxwcM/mPk8Zm//jjGa81EXcTF5kREREQmYpAiIiIiMhGDlJmysrLCs88+CysrK6lL6Rc8PvM32I9xsB8fMPiPkcdn/uRwjFxsTkRERGQizkgRERERmYhBioiIiMhEDFJEREREJmKQIiIiIjIRg5SMpaamIigoCNbW1oiLi0N2dvZVx3/11VcYMWIErK2tMWrUKGzatGmAKjVNb45vzZo1UCgURg9ra+sBrLZ3MjMzkZycDI1GA4VCgQ0bNlzzOenp6Rg3bhysrKwQGhqKNWvW9Hudpurt8aWnp/f4/BQKBSoqKgam4F56+eWXMWHCBDg4OMDT0xPz5s1DXl7eNZ9nTn+DphyjOf0drlq1CqNHj9Y3apw4cSI2b9581eeY0+fX2+Mzp8/ucl555RUoFAosXbr0quOk+AwZpGRq3bp1WLZsGZ599lkcPHgQ0dHRmDVrFqqqqi47fs+ePVi0aBF+//vf49ChQ5g3bx7mzZuH3NzcAa78+vT2+ACxc215ebn+UVxcPIAV905zczOio6ORmpp6XeOLioowZ84cJCYm4vDhw1i6dCkeeOABbN26tZ8rNU1vj++ivLw8o8/Q09Oznyq8MRkZGViyZAl++eUXbN++HZ2dnZg5cyaam5uv+Bxz+xs05RgB8/k79PPzwyuvvIIDBw5g//79mDZtGm6//XYcO3bssuPN7fPr7fEB5vPZXWrfvn344IMPMHr06KuOk+wzFEiWYmNjhSVLluh/1mq1gkajEV5++eXLjr/zzjuFOXPmGG2Li4sT/vCHP/Rrnabq7fF9/PHHgpOT0wBV17cACOvXr7/qmKeffloYOXKk0ba77rpLmDVrVj9W1jeu5/jS0tIEAMKFCxcGpKa+VlVVJQAQMjIyrjjG3P4GL3U9x2jOf4eCIAguLi7Cf/7zn8vuM/fPTxCufnzm+tk1NjYKYWFhwvbt24X4+Hjh8ccfv+JYqT5DzkjJUEdHBw4cOIAZM2botymVSsyYMQNZWVmXfU5WVpbReACYNWvWFcdLyZTjA4CmpiYEBgbC39//mv/Py9yY0+d3I8aMGQMfHx/ccsst2L17t9TlXLf6+noAgKur6xXHmPtneD3HCJjn36FWq8UXX3yB5uZmTJw48bJjzPnzu57jA8zzs1uyZAnmzJnT47O5HKk+QwYpGaqpqYFWq4WXl5fRdi8vryuuKamoqOjVeCmZcnzh4eH46KOP8N133+Gzzz6DTqfDpEmTcO7cuYEoud9d6fNraGhAa2urRFX1HR8fH7z//vv45ptv8M0338Df3x8JCQk4ePCg1KVdk06nw9KlSzF58mRERUVdcZw5/Q1e6nqP0dz+Do8ePQp7e3tYWVnh4Ycfxvr16xEZGXnZseb4+fXm+MztswOAL774AgcPHsTLL798XeOl+gwt+vXVifrIxIkTjf6f1qRJkxAREYEPPvgAL7zwgoSV0fUIDw9HeHi4/udJkyahsLAQb7/9NtauXSthZde2ZMkS5Obm4ueff5a6lH5zvcdobn+H4eHhOHz4MOrr6/H1118jJSUFGRkZVwwb5qY3x2dun11JSQkef/xxbN++XfaL4hmkZMjd3R0qlQqVlZVG2ysrK+Ht7X3Z53h7e/dqvJRMOb5LWVpaYuzYsSgoKOiPEgfclT4/R0dH2NjYSFRV/4qNjZV9OHn00Ufxww8/IDMzE35+flcda05/g7/Wm2O8lNz/DtVqNUJDQwEAMTEx2LdvH9555x188MEHPcaa4+fXm+O7lNw/uwMHDqCqqgrjxo3Tb9NqtcjMzMTKlSvR3t4OlUpl9BypPkOe2pMhtVqNmJgY7Ny5U79Np9Nh586dVzz/PXHiRKPxALB9+/arni+XiinHdymtVoujR4/Cx8env8ocUOb0+fWVw4cPy/bzEwQBjz76KNavX49du3YhODj4ms8xt8/QlGO8lLn9Hep0OrS3t192n7l9fpdzteO7lNw/u+nTp+Po0aM4fPiw/jF+/HjcfffdOHz4cI8QBUj4GfbrUnYy2RdffCFYWVkJa9asEY4fPy489NBDgrOzs1BRUSEIgiDcc889wvLly/Xjd+/eLVhYWAhvvPGGcOLECeHZZ58VLC0thaNHj0p1CFfV2+P75z//KWzdulUoLCwUDhw4IPz2t78VrK2thWPHjkl1CFfV2NgoHDp0SDh06JAAQHjrrbeEQ4cOCcXFxYIgCMLy5cuFe+65Rz/+9OnTgq2trfDUU08JJ06cEFJTUwWVSiVs2bJFqkO4qt4e39tvvy1s2LBBOHXqlHD06FHh8ccfF5RKpbBjxw6pDuGqHnnkEcHJyUlIT08XysvL9Y+Wlhb9GHP/GzTlGM3p73D58uVCRkaGUFRUJBw5ckRYvny5oFAohG3btgmCYP6fX2+Pz5w+uyu59Ko9uXyGDFIy9t577wkBAQGCWq0WYmNjhV9++UW/Lz4+XkhJSTEa/+WXXwrDhw8X1Gq1MHLkSOHHH38c4Ip7pzfHt3TpUv1YLy8v4dZbbxUOHjwoQdXX5+Ll/pc+Lh5TSkqKEB8f3+M5Y8aMEdRqtRASEiJ8/PHHA1739ert8b366qvCsGHDBGtra8HV1VVISEgQdu3aJU3x1+FyxwbA6DMx979BU47RnP4O77//fiEwMFBQq9WCh4eHMH36dH3IEATz//x6e3zm9NldyaVBSi6foUIQBKF/57yIiIiIBieukSIiIiIyEYMUERERkYkYpIiIiIhMxCBFREREZCIGKSIiIiITMUgRERERmYhBioiIiMhEDFJEREREJmKQIiIaQAqFAhs2bJC6DCLqIwxSRDRk3HvvvVAoFD0es2fPlro0IjJTFlIXQEQ0kGbPno2PP/7YaJuVlZVE1RCRueOMFBENKVZWVvD29jZ6uLi4ABBPu61atQpJSUmwsbFBSEgIvv76a6PnHz16FNOmTYONjQ3c3Nzw0EMPoampyWjMRx99hJEjR8LKygo+Pj549NFHjfbX1NRg/vz5sLW1RVhYGDZu3Ni/B01E/YZBiojoV/7xj39g4cKFyMnJwd13343f/va3OHHiBACgubkZs2bNgouLC/bt24evvvoKO3bsMApKq1atwpIlS/DQQw/h6NGj2LhxI0JDQ43e45///CfuvPNOHDlyBLfeeivuvvtu1NbWDuhxElEfEYiIhoiUlBRBpVIJdnZ2Ro8XX3xREARBACA8/PDDRs+Ji4sTHnnkEUEQBOHDDz8UXFxchKamJv3+H3/8UVAqlUJFRYUgCIKg0WiEv/3tb1esAYDw97//Xf9zU1OTAEDYvHlznx0nEQ0crpEioiElMTERq1atMtrm6uqq/++JEyca7Zs4cSIOHz4MADhx4gSio6NhZ2en3z958mTodDrk5eVBoVCgrKwM06dPv2oNo0eP1v+3nZ0dHB0dUVVVZeohEZGEGKSIaEixs7Prcaqtr9jY2FzXOEtLS6OfFQoFdDpdf5RERP2Ma6SIiH7ll19+6fFzREQEACAiIgI5OTlobm7W79+9ezeUSiXCw8Ph4OCAoKAg7Ny5c0BrJiLpcEaKiIaU9vZ2VFRUGG2zsLCAu7s7AOCrr77C+PHjMWXKFHz++efIzs7G6tWrAQB33303nn32WaSkpOC5555DdXU1HnvsMdxzzz3w8vICADz33HN4+OGH4enpiaSkJDQ2NmL37t147LHHBvZAiWhAMEgR0ZCyZcsW+Pj4GG0LDw/HyZMnAYhX1H3xxRf44x//CB8fH/z3v/9FZGQkAMDW1hZbt27F448/jgkTJsDW1hYLFy7EW2+9pX+tlJQUtLW14e2338aTTz4Jd3d33HHHHQN3gEQ0oBSCIAhSF0FEJAcKhQLr16/HvHnzpC6FiMwE10gRERERmYhBioiIiMhEXCNFRNSNKx2IqLc4I0VERERkIgYpIiIiIhMxSBERERGZiEGKiIiIyEQMUkREREQmYpAiIiIiMhGDFBEREZGJGKSIiIiITPT/ASOnRyRBhzUFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MESH: reference_mesh_large.csv\n",
      "reconstruction error tensor(9.1108e-27, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.1272395\n",
      "Mean relative error for latent =  0.9648970429023559\n",
      "Minimum relative error for latent =  0.85728574\n",
      "\n",
      "Maximum absolute error for field  =  67.13029841506109\n",
      "Mean absolute error for field  =  28.22893037527601\n",
      "Minimum absolute error for field  =  11.515028085327973\n",
      "\n",
      "Maximum relative error for field  =  0.682847925537893\n",
      "Mean relative error for field  =  0.3588289814043636\n",
      "Minimum relative error for field  =  0.1671819125793226\n",
      "\n",
      "TEST MESH: reference_mesh.csv\n",
      "reconstruction error tensor(4.0544e-27, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.1216075\n",
      "Mean relative error for latent =  0.9640367620370605\n",
      "Minimum relative error for latent =  0.84948266\n",
      "\n",
      "Maximum absolute error for field  =  44.5874582568028\n",
      "Mean absolute error for field  =  18.756708627333712\n",
      "Minimum absolute error for field  =  7.653587461644862\n",
      "\n",
      "Maximum relative error for field  =  0.6807423897442626\n",
      "Mean relative error for field  =  0.3587416238442089\n",
      "Minimum relative error for field  =  0.16717979242838268\n",
      "\n",
      "TEST MESH: reference_mesh_small.csv\n",
      "reconstruction error tensor(1.0720e-27, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.1214515\n",
      "Mean relative error for latent =  0.964803927578032\n",
      "Minimum relative error for latent =  0.8792782\n",
      "\n",
      "Maximum absolute error for field  =  22.653827865048374\n",
      "Mean absolute error for field  =  9.471165521392647\n",
      "Minimum absolute error for field  =  3.8405726264080697\n",
      "\n",
      "Maximum relative error for field  =  0.6820249284907727\n",
      "Mean relative error for field  =  0.35911086025515326\n",
      "Minimum relative error for field  =  0.16703802234005036\n",
      "\n",
      "TEST MESH: reference_mesh_tiny.csv\n",
      "reconstruction error tensor(2.1232e-28, dtype=torch.float64)\n",
      "\n",
      "Maximum relative error for latent  =  1.0974561\n",
      "Mean relative error for latent =  0.9781630491329865\n",
      "Minimum relative error for latent =  0.89290273\n",
      "\n",
      "Maximum absolute error for field  =  9.1664718996972\n",
      "Mean absolute error for field  =  3.834572860670892\n",
      "Minimum absolute error for field  =  1.574497028675647\n",
      "\n",
      "Maximum relative error for field  =  0.6833796194582227\n",
      "Mean relative error for field  =  0.360483181573027\n",
      "Minimum relative error for field  =  0.17036449821803124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_mesh_names)):\n",
    "    print(f'TEST MESH: {test_mesh_names[i]}')\n",
    "    scale, U = get_scaled_data(test_solution_names[i])\n",
    "    U = U.to('cpu').float()\n",
    "    df = pd.read_csv(test_mesh_names[i], header=None).values\n",
    "\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    print_results(model, df, U, scale, params.to('cpu'))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
